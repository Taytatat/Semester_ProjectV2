# -*- coding: utf-8 -*-
"""SpellmanModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xQ-0IfFD7Is23YyYwGCD0cyyqIa2jey7
"""

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "Spellman CDC 2022 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_22_df = raw_df.iloc[6:].copy()
sp_22_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_22_df = sp_22_df.loc[:, sp_22_df.columns.notnull()]
sp_22_df = sp_22_df.dropna(axis=1, how='all')

# Optional: Reset index
sp_22_df.reset_index(drop=True, inplace=True)
sp_22_df['Year'] = 2022
# Preview result
display(sp_22_df.head())
sp_22_df.to_csv("sp_full_dataset_22.csv", index=False)

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "Spellman CDC 2023 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_23_df = raw_df.iloc[6:].copy()
sp_23_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_23_df = sp_23_df.loc[:, sp_23_df.columns.notnull()]
sp_23_df = sp_23_df.dropna(axis=1, how='all')

# Optional: Reset index
sp_23_df.reset_index(drop=True, inplace=True)
sp_23_df['Year'] = 2023

# Preview result
display(sp_23_df.head())
sp_23_df.to_csv("sp_full_dataset_23.csv", index=False)

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "/content/Spellman CDC 2024 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_24_df = raw_df.iloc[6:].copy()
sp_24_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_24_df = sp_24_df.loc[:, sp_24_df.columns.notnull()]
sp_24_df = sp_24_df.dropna(axis=1, how='all')

# Optional: Reset index
sp_24_df.reset_index(drop=True, inplace=True)
sp_24_df['Year'] = 2024

# Preview result
display(sp_24_df.head())
sp_24_df.to_csv("sp_full_dataset_24.csv", index=False)

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "Spellman CDC 2025 01012025-02282025 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_25_df = raw_df.iloc[6:].copy()
sp_25_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_25_df = sp_25_df.loc[:, sp_25_df.columns.notnull()]
sp_25_df = sp_25_df.dropna(axis=1, how='all')

# Optional: Reset index
sp_25_df.reset_index(drop=True, inplace=True)
sp_25_df['Year'] = 2025

# Preview result
display(sp_25_df.head())
sp_25_df.to_csv("sp_full_dataset.csv", index=False)

#check for duplicates
print("Duplicate columns in sp_22_df:", sp_22_df.columns[sp_22_df.columns.duplicated()])
print("Duplicate columns in sp_23_df:", sp_23_df.columns[sp_23_df.columns.duplicated()])
print("Duplicate columns in sp_24_df:", sp_24_df.columns[sp_24_df.columns.duplicated()])
print("Duplicate columns in sp_25_df:", sp_25_df.columns[sp_25_df.columns.duplicated()])

# Concatenate all cleaned DataFrames into one
sp = pd.concat([sp_22_df, sp_23_df, sp_24_df, sp_25_df], axis=0, ignore_index=True)

# Reorder columns by month
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

# Separate the first 5 columns
first_columns = sp.columns[:4].tolist()

# Identify month-related columns (after the first 5 columns)
month_columns = [col for col in sp.columns[4:] if any(col.startswith(month) for month in month_order)]
other_columns = [col for col in sp.columns[4:] if col not in month_columns]

# Sort month columns by month order
sorted_month_columns = sorted(month_columns, key=lambda col: (month_order.index(col[:3]), col))

# Combine the first 5 columns, sorted month columns, and other columns
sp_time = sp[first_columns + sorted_month_columns + other_columns]

#Replace all Nan with 0s
sp_time = sp_time.fillna(0)

#commneted this out because dont want this, need text to stay in these columns# Convert month-related columns to binomial code
#for col in sorted_month_columns:
 #   if "IN" in col:
    #    sp[col] = sp[col].apply(lambda x: 1 if pd.notna(x) else 0)  # 1 for check-in
  #  elif "OUT" in col:
   #     sp[col] = sp[col].apply(lambda x: 2 if pd.notna(x) else 0)  # 2 for check-out

# Display the cleaned and transformed DataFrame
print("Cleaned and Transformed Combined DataFrame Preview:")
display(sp_time)

# Export the transformed DataFrame to a CSV file
sp_time.to_csv("combined_sp_time.csv", index=False)

# drop _OUT columns (created a seperate datafram without the out columns) this for Time sp dataframe
sp_in_time = sp_time.loc[:, ~sp_time.columns.str.endswith('_OUT')]
# reset index
sp_in_time.reset_index(drop=True, inplace=True)
#save to csv
sp_in_time.to_csv("combined_sp_binomial_no_out_time.csv", index=False)

display(sp_in_time)

# drop _IN columns (created a seperate datafram without the in columns)
sp_out_time = sp_time.loc[:, ~sp_time.columns.str.endswith('_IN')]
# reset index
sp_out_time.reset_index(drop=True, inplace=True)
#save to csv
sp_out_time.to_csv("combined_sp_binomial_no_in_time.csv", index=False)

#now will further condense/ clean data with only IN columns (for columns with times)
#STARTING WITH TIME IN DATA
import pandas as pd

metadata_columns = ['Record ID', 'Student Status', 'Room', 'Tags', 'Year']  # Include 'Year' in metadata

# Identify date columns (columns with month names)
date_columns = [col for col in sp_in_time.columns if any(month in col for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                                                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])]

# Melt the DataFrame to create a long format
sp_long_in_time = sp_in_time.melt(id_vars=metadata_columns,
                            value_vars=date_columns,
                            var_name='Date_Event',
                            value_name='Time_IN')
#display(sp_long_in_time)

# Split 'Date_Event' into 'Date' and 'Event' (e.g., IN/OUT)
#sp_long[['Date', 'Event']] = sp_long['Date_Event'].str.split('_', expand=True)

# Use the existing 'Year' column to construct the full date
#sp_long['Date'] = pd.to_datetime(sp_long['Date'] + " " + sp_long['Year'].astype(str), format='%b %d %Y')



#_____________GOING TO TRY TO FIX ERROR ACCURING WIH SPLTTING THE DATE
# Split 'Date_Event' into 'Month Day' and 'Event' (e.g., Jan 02 and IN)
sp_long_in_time[['Month_Day', 'Event_IN']] = sp_long_in_time['Date_Event'].str.rsplit('_', n=1, expand=True)

# Clean 'Month_Day' string and construct the full date
sp_long_in_time['Month_Day'] = sp_long_in_time['Month_Day'].str.strip()
date_strings = sp_long_in_time['Month_Day'] + " " + sp_long_in_time['Year'].astype(str)
sp_long_in_time['Date'] = pd.to_datetime(date_strings, format='%b %d %Y', errors='coerce')

# Drop rows with invalid dates or zero values
sp_long_in_time = sp_long_in_time[(~sp_long_in_time['Date'].isna()) & (sp_long_in_time['Time_IN'] != 0)]

# Drop temporary columns
sp_long_in_time.drop(columns=['Date_Event', 'Month_Day', 'Year'], inplace=True)





#______________END


# Drop the original 'Date_Event' and 'Year' columns (optional)
#sp_long.drop(columns=['Date_Event', 'Year'], inplace=True)

# Filter out rows where 'Value' is 0 (optional, if you only want rows with attendance data)
#sp_long = sp_long[sp_long['Value'] != 0]

# Reset the index
sp_long_in_time.reset_index(drop=True, inplace=True)

# Preview the reshaped DataFrame
display(sp_long_in_time.head())

# Save the reshaped DataFrame to a CSV file
sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)

#now will further condense/ clean data with only OUT columns (for columns with times)
import pandas as pd

metadata_columns = ['Record ID', 'Student Status', 'Room', 'Tags', 'Year']  # Include 'Year' in metadata

# Identify date columns (columns with month names)
date_columns = [col for col in sp_out_time.columns if any(month in col for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                                                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])]

# Melt the DataFrame to create a long format
sp_long_out_time = sp_out_time.melt(id_vars=metadata_columns,
                            value_vars=date_columns,
                            var_name='Date_Event',
                            value_name='Time_OUT')


# Split 'Date_Event' into 'Month Day' and 'Event' (e.g., Jan 02 and IN)
sp_long_out_time[['Month_Day', 'Event_OUT']] =sp_long_out_time['Date_Event'].str.rsplit('_', n=1, expand=True)

# Clean 'Month_Day' string and construct the full date
sp_long_out_time['Month_Day'] = sp_long_out_time['Month_Day'].str.strip()
date_strings = sp_long_out_time['Month_Day'] + " " + sp_long_out_time['Year'].astype(str)
sp_long_out_time['Date'] = pd.to_datetime(date_strings, format='%b %d %Y', errors='coerce')

# Drop rows with invalid dates or zero values
sp_long_out_time = sp_long_out_time[(~sp_long_out_time['Date'].isna()) & (sp_long_out_time['Time_OUT'] != 0)]

# Drop temporary columns
sp_long_out_time.drop(columns=['Date_Event', 'Month_Day', 'Year'], inplace=True)



# Reset the index
sp_long_out_time.reset_index(drop=True, inplace=True)

# Preview the reshaped DataFrame
display(sp_long_out_time.head())

# Save the reshaped DataFrame to a CSV file
sp_long_out_time.to_csv("sp_long_out_time_format.csv", index=False)

#Now going to pop the out column from sp_long_out so that we can then add it to the sp_long_in data set
import pandas

#taking out the event out column because it is redundant (removing from sp_long_out_time )
#remove_event_out = sp_long_out_time.pop('Event_OUT')

#taking out the event out column because it is redundant (removing from sp_long_in_time )
#remove_event_in = sp_long_in_time.pop('Event_IN')

#taking out the time out column because this is the one we want to add to the other dataframe
remove_time_out = sp_long_out_time.pop('Time_OUT')

display(sp_long_out_time.head())

#now going to add the removed column Time_OUT to the sp_long_in_time dataframe
sp_long_in_time['Time_OUT'] = remove_time_out

#display newly added colum in the dataframe
display(sp_long_in_time.head())

#going to reset the values of the dataframe for sp long time in for better readabilty

# State the colum order wanted
desired_column_order = ['Record ID', 'Student Status', 'Room', 'Tags', 'Time_IN', 'Time_OUT', 'Date']

# Reorder columns by setting equal to orignal data frame
sp_long_in_time = sp_long_in_time[desired_column_order]

# Display the DataFrame with reordered columns
display(sp_long_in_time.head())

#save new format to csv file
sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)

#now going to extract the times from the Time_In and Time_Out

import pandas as pd
import re
from dateutil.parser import parse

def extract_time(text):
    match = re.search(r'(\d{1,2}:\d{2} (?:AM|PM))', str(text))
    if match:
        return match.group(1)
    else:
        return None

#apply function to date frame columns to extract time
sp_long_in_time['Time_IN'] = sp_long_in_time['Time_IN'].apply(extract_time)
sp_long_in_time['Time_OUT'] = sp_long_in_time['Time_OUT'].apply(extract_time)

#display times only in data frame
display(sp_long_in_time.head())

from datetime import datetime, timedelta
#check data type for all columns, just to see what is already a datetime
print(sp_long_in_time.dtypes)

#now going to combine the date and time columns together and then convert them into date time objects

display(sp_long_in_time.head())

#convert time component from 'Time_IN' and 'Time_OUT' to datetime.time
#replace nat values  with a default time (00:00:00)
default_time = datetime.min.time()  # or any other desired default time
sp_long_in_time['Time_IN'] = pd.to_datetime(sp_long_in_time['Time_IN']).dt.time.fillna(default_time)

sp_long_in_time['Time_OUT'] = pd.to_datetime(sp_long_in_time['Time_OUT']).dt.time.fillna(default_time)

#convert column to datetime.date if it's a Timestamp
sp_long_in_time['Date'] = pd.to_datetime(sp_long_in_time['Date']).dt.date

print(sp_long_in_time.dtypes)

#now going to combine the date and time columns together and then convert them into date time objects

from datetime import datetime
#check data type for all columns
print(sp_long_in_time.dtypes)





# datetime.combine
sp_long_in_time['Time_IN'] = sp_long_in_time.apply(lambda row: datetime.combine(row['Date'], row['Time_IN']), axis=1)
sp_long_in_time['Time_OUT'] = sp_long_in_time.apply(lambda row: datetime.combine(row['Date'], row['Time_OUT']), axis=1)

display(sp_long_in_time.head())



sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)


#DO NOT DELETE THE DATE COLUMN!!! LEAVE IT

#now sort the dataframe by date (earliest)
sp_long_in_time = sp_long_in_time.sort_values(by=['Time_IN'])

display(sp_long_in_time.head())

#save to csv
sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)

#Find all of the unique room names included on data frame
unique_rooms = sp_long_in_time['Room'].unique()
print(unique_rooms)

#Starting with sp data going to create new dataframes for each Room

#Start with Room for Dinosaur Stomp

#create new dataframe to filter out only prek-k1 entries
dino_stmp_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Dinosaur Stomp']

#display new dataframe
display(dino_stmp_sp.head())

#save new data frame to a csv
dino_stmp_sp.to_csv("dino_stmp_sp.csv", index=False)

#determine daily student count in 30 minute intervals
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=dino_stmp_sp['Time_IN'].min().floor('30min'),
                          end=dino_stmp_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = dino_stmp_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (dino_stmp_sp['Time_IN'] <= end) & (dino_stmp_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Dinosaur Stomp', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
dino_stmp_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(dino_stmp_sp_30min_counts)

#save to csv
dino_stmp_sp_30min_counts.to_csv("dino_stmp_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#prek ratio is 12 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 12:
        return 1  # 1 staff member for up to 12 students
    elif student_count <= 24:
        return 2  # 2 staff members for 13-24 students
    elif student_count <= 36:
        return 3  # 3 staff members for 25-36 students
    elif student_count <= 48:
        return 4  # 4 staff members for 37-48 students
    else:
        return "Error: count ratio not accounted for"

# create the 'Staffing Needs' column with funcyion
dino_stmp_sp_30min_counts['Staffing Needs'] = dino_stmp_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(dino_stmp_sp_30min_counts)

#save to csv
dino_stmp_sp_30min_counts.to_csv("dino_stmp_sp_30min_counts.csv", index=False)

#create data frame for Wild Things

#create new dataframe to filter out entries
wild_th_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Wild Things']

#display new dataframe
display(wild_th_sp.head())

#save new data frame to a csv
wild_th_sp.to_csv("wild_th_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# 30 min time interval based on time and time out columns
time_range = pd.date_range(start=wild_th_sp['Time_IN'].min().floor('30min'),
                          end=wild_th_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = wild_th_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (wild_th_sp['Time_IN'] <= end) & (wild_th_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Wild Things', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
wild_th_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(wild_th_sp_30min_counts)

#save to csv
wild_th_sp_30min_counts.to_csv("wild_th_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#preschool ratio is 10 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 10:
        return 1  # 1 staff member for up to 10 students
    elif student_count <= 20:
        return 2  # 2 staff members for 11-20 students
    elif student_count <= 30:
        return 3  # 3 staff members for 21-30 students
    elif student_count <= 40:
        return 4  # 4 staff members for 31-40 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
wild_th_sp_30min_counts['Staffing Needs'] = wild_th_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(wild_th_sp_30min_counts)

#save to csv
wild_th_sp_30min_counts.to_csv("wild_th_sp_30min_counts.csv", index=False)

#create data frame for Monkeys

#create new dataframe to filter out entries
monk_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Monkeys']

#display new dataframe
display(monk_sp.head())

#save new data frame to a csv
monk_sp.to_csv("monk_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=monk_sp['Time_IN'].min().floor('30min'),
                          end=monk_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = monk_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (monk_sp['Time_IN'] <= end) & (monk_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Monkeys', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

monk_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(monk_sp_30min_counts)

#save to csv
monk_sp_30min_counts.to_csv("monk_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Toddler ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
monk_sp_30min_counts['Staffing Needs'] = monk_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(monk_sp_30min_counts)

#save to csv
monk_sp_30min_counts.to_csv("monk_sp_30min_counts.csv", index=False)

#Starting with sp data going to create new dataframes for each Room

#Start with Room for Rainbow Fish

#create new dataframe to filter out only prek-k1 entries
rain_fs_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Rainbow Fish']

#display new dataframe
display(rain_fs_sp.head())

#save new data frame to a csv
rain_fs_sp.to_csv("rain_fs_sp.csv", index=False)

#determine daily student count in 30 minute intervals
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=rain_fs_sp['Time_IN'].min().floor('30min'),
                          end=rain_fs_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = rain_fs_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (rain_fs_sp['Time_IN'] <= end) & (rain_fs_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Rainbow Fish', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
rain_fs_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(rain_fs_sp_30min_counts)

#save to csv
rain_fs_sp_30min_counts.to_csv("rain_fs_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#preschool ratio is 10 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 10:
        return 1  # 1 staff member for up to 10 students
    elif student_count <= 20:
        return 2  # 2 staff members for 11-20 students
    elif student_count <= 30:
        return 3  # 3 staff members for 21-30 students
    elif student_count <= 40:
        return 4  # 4 staff members for 31-40 students
    else:
        return "Error: count ratio not accounted for"

# create the 'Staffing Needs' column with funcyion
rain_fs_sp_30min_counts['Staffing Needs'] = rain_fs_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(rain_fs_sp_30min_counts)

#save to csv
rain_fs_sp_30min_counts.to_csv("rain_fs_sp_30min_counts.csv", index=False)

#create data frame for Goodnight Moon

#create new dataframe to filter out entries
gdnt_mn_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Goodnight Moon']

#display new dataframe
display(gdnt_mn_sp.head())

#save new data frame to a csv
gdnt_mn_sp.to_csv("gdnt_mn_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = gdnt_mn_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (gdnt_mn_sp['Time_IN'] <= end) & (gdnt_mn_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Goodnight Moon', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

gdnt_mn_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(gdnt_mn_sp_30min_counts)

#save to csv
gdnt_mn_sp_30min_counts.to_csv("gdnt_mn_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Infant ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
gdnt_mn_sp_30min_counts['Staffing Needs'] = gdnt_mn_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(gdnt_mn_sp_30min_counts)

#save to csv
gdnt_mn_sp_30min_counts.to_csv("gdnt_mn_sp_30min_counts.csv", index=False)

#create data frame for Pandas

#create new dataframe to filter out entries
pnds_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Pandas']

#display new dataframe
display(pnds_sp.head())

#save new data frame to a csv
pnds_sp.to_csv("pnds_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=pnds_sp['Time_IN'].min().floor('30min'),
                          end=pnds_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = pnds_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (pnds_sp['Time_IN'] <= end) & (pnds_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Pandas', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

pnds_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(pnds_sp_30min_counts)

#save to csv
pnds_sp_30min_counts.to_csv("pnds_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#toddler have 6:1 ratio

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
pnds_sp_30min_counts['Staffing Needs'] = pnds_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(pnds_sp_30min_counts)

#save to csv
pnds_sp_30min_counts.to_csv("pnds_sp_30min_counts.csv", index=False)

#create data frame for Rabbits

#create new dataframe to filter out entries
rabts_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Rabbits']

#display new dataframe
display(rabts_sp.head())

#save new data frame to a csv
rabts_sp.to_csv("rabts_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=rabts_sp['Time_IN'].min().floor('30min'),
                          end=rabts_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = rabts_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (rabts_sp['Time_IN'] <= end) & (rabts_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Rabbits', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

rabts_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(rabts_sp_30min_counts)

#save to csv
rabts_sp_30min_counts.to_csv("rabts_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#toddler have 6:1 ratio

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
rabts_sp_30min_counts['Staffing Needs'] = rabts_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(rabts_sp_30min_counts)

#save to csv
rabts_sp_30min_counts.to_csv("rabts_sp_30min_counts.csv", index=False)

#create data frame for Llamas Llamas

#create new dataframe to filter out entries
lama_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Llamas Llamas']

#display new dataframe
display(lama_sp.head())

#save new data frame to a csv
lama_sp.to_csv("lama_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = lama_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (lama_sp['Time_IN'] <= end) & (lama_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Llamas Llamas', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

lama_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(lama_sp_30min_counts)

#save to csv
lama_sp_30min_counts.to_csv("lama_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Multi Age ratio is 4 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 4:
        return 1  # 1 staff member for up to 4 students
    elif student_count <= 8:
        return 2  # 2 staff members for 5-8 students
    elif student_count <= 12:
        return 3  # 3 staff members for 9-12 students
    elif student_count <= 16:
        return 4  # 4 staff members for 13-16 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
lama_sp_30min_counts['Staffing Needs'] = lama_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(lama_sp_30min_counts)

#save to csv
lama_sp_30min_counts.to_csv("lama_sp_30min_counts.csv", index=False)

#create data frame for Hungry Caterpillars

#create new dataframe to filter out entries
hun_cat_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Hungry Caterpillars']

#display new dataframe
display(hun_cat_sp.head())

#save new data frame to a csv
hun_cat_sp.to_csv("hun_cat_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = hun_cat_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (hun_cat_sp['Time_IN'] <= end) & (hun_cat_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Hungry Caterpillars', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))

#make a new data frame, with new variable interval that will hold the 30 mins at each start time
#gramp_pre_sp_30min_counts = pd.DataFrame({'Interval': time_range[:-1], 'Count': counts})
#now I can call on the data frame in a cool way

hun_cat_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(hun_cat_sp_30min_counts)

#save to csv
hun_cat_sp_30min_counts.to_csv("hun_cat_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Multi Age ratio is 4 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 4:
        return 1  # 1 staff member for up to 4 students
    elif student_count <= 8:
        return 2  # 2 staff members for 5-8 students
    elif student_count <= 12:
        return 3  # 3 staff members for 9-12 students
    elif student_count <= 16:
        return 4  # 4 staff members for 13-16 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
hun_cat_sp_30min_counts['Staffing Needs'] = hun_cat_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(hun_cat_sp_30min_counts)

#save to csv
hun_cat_sp_30min_counts.to_csv("hun_cat_sp_30min_counts.csv", index=False)

#create data frame for House Pooh

#create new dataframe to filter out entries
hos_ph_sp = sp_long_in_time[sp_long_in_time['Room'] == 'House Pooh']

#display new dataframe
display(hos_ph_sp.head())

#save new data frame to a csv
hos_ph_sp.to_csv("hos_ph_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = hos_ph_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (hos_ph_sp['Time_IN'] <= end) & (hos_ph_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'House Pooh', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

hos_ph_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(hos_ph_sp_30min_counts)

#save to csv
hos_ph_sp_30min_counts.to_csv("hos_ph_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Infant ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
hos_ph_sp_30min_counts['Staffing Needs'] = hos_ph_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(hos_ph_sp_30min_counts)

#save to csv
hos_ph_sp_30min_counts.to_csv("hos_ph_sp_30min_counts.csv", index=False)

#now going to combine all 30 minute dataframes with the counts, into 1 data frame

sp_count_full = pd.concat([dino_stmp_sp_30min_counts, rain_fs_sp_30min_counts, wild_th_sp_30min_counts, monk_sp_30min_counts, gdnt_mn_sp_30min_counts, pnds_sp_30min_counts, rabts_sp_30min_counts, lama_sp_30min_counts, hun_cat_sp_30min_counts, hos_ph_sp_30min_counts  ])

display(sp_count_full)

#save to csv
sp_count_full.to_csv("sp_count_full.csv", index=False)

"""Next: Create the Random forests for each room and create the forecasts"""

#Random forest for Dinosaur Stomp


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


dino_stmp_data_rf = sp_count_full[sp_count_full['Room'] == 'Dinosaur Stomp']

dino_stmp_data_rf['hour'] = dino_stmp_data_rf['Interval'].dt.hour
dino_stmp_data_rf['year'] = dino_stmp_data_rf['Interval'].dt.year
dino_stmp_data_rf['month'] = dino_stmp_data_rf['Interval'].dt.month
dino_stmp_data_rf['day'] = dino_stmp_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = dino_stmp_data_rf[features]
Y = dino_stmp_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_dino_stmp
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_dino_stmp = pd.DataFrame({'Interval': future_intervals})


future_data_rf_dino_stmp['hour'] = future_data_rf_dino_stmp['Interval'].dt.hour
future_data_rf_dino_stmp['year'] = future_data_rf_dino_stmp['Interval'].dt.year
future_data_rf_dino_stmp['month'] = future_data_rf_dino_stmp['Interval'].dt.month
future_data_rf_dino_stmp['day'] = future_data_rf_dino_stmp['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_dino_stmp = fclf.predict(future_data_rf_dino_stmp[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_dino_stmp = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_dino_stmp[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_dino_stmp[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_dino_stmp )

forecast_rf_dino_stmp .to_csv("forecast_rf_dino_stmp .csv", index=False)

#Random forest for Rainbow Fish


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


rain_fs_data_rf = sp_count_full[sp_count_full['Room'] == 'Rainbow Fish']

rain_fs_data_rf['hour'] = rain_fs_data_rf['Interval'].dt.hour
rain_fs_data_rf['year'] = rain_fs_data_rf['Interval'].dt.year
rain_fs_data_rf['month'] = rain_fs_data_rf['Interval'].dt.month
rain_fs_data_rf['day'] = rain_fs_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = rain_fs_data_rf[features]
Y = rain_fs_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_rain_fs
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_rain_fs = pd.DataFrame({'Interval': future_intervals})


future_data_rf_rain_fs['hour'] = future_data_rf_rain_fs['Interval'].dt.hour
future_data_rf_rain_fs['year'] = future_data_rf_rain_fs['Interval'].dt.year
future_data_rf_rain_fs['month'] = future_data_rf_rain_fs['Interval'].dt.month
future_data_rf_rain_fs['day'] = future_data_rf_rain_fs['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_rain_fs = fclf.predict(future_data_rf_rain_fs[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_rain_fs = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_rain_fs[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_rain_fs[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_rain_fs )

forecast_rf_rain_fs .to_csv("forecast_rf_rain_fs .csv", index=False)

#Random forest for Wild Things


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


wild_th_data_rf = sp_count_full[sp_count_full['Room'] == 'Wild Things']

wild_th_data_rf['hour'] = wild_th_data_rf['Interval'].dt.hour
wild_th_data_rf['year'] = wild_th_data_rf['Interval'].dt.year
wild_th_data_rf['month'] = wild_th_data_rf['Interval'].dt.month
wild_th_data_rf['day'] = wild_th_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = wild_th_data_rf[features]
Y = wild_th_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_wild_th
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_wild_th = pd.DataFrame({'Interval': future_intervals})


future_data_rf_wild_th['hour'] = future_data_rf_wild_th['Interval'].dt.hour
future_data_rf_wild_th['year'] = future_data_rf_wild_th['Interval'].dt.year
future_data_rf_wild_th['month'] = future_data_rf_wild_th['Interval'].dt.month
future_data_rf_wild_th['day'] = future_data_rf_wild_th['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_wild_th = fclf.predict(future_data_rf_wild_th[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_wild_th = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_wild_th[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_wild_th[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_wild_th )

forecast_rf_wild_th .to_csv("forecast_rf_wild_th .csv", index=False)

#Random forest for Monkeys


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


monk_data_rf = sp_count_full[sp_count_full['Room'] == 'Monkeys']

monk_data_rf['hour'] = monk_data_rf['Interval'].dt.hour
monk_data_rf['year'] = monk_data_rf['Interval'].dt.year
monk_data_rf['month'] = monk_data_rf['Interval'].dt.month
monk_data_rf['day'] = monk_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = monk_data_rf[features]
Y = monk_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_monk
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_monk = pd.DataFrame({'Interval': future_intervals})


future_data_rf_monk['hour'] = future_data_rf_monk['Interval'].dt.hour
future_data_rf_monk['year'] = future_data_rf_monk['Interval'].dt.year
future_data_rf_monk['month'] = future_data_rf_monk['Interval'].dt.month
future_data_rf_monk['day'] = future_data_rf_monk['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_monk = fclf.predict(future_data_rf_monk[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_monk = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_monk[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_monk[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_monk )

forecast_rf_monk .to_csv("forecast_rf_monk .csv", index=False)

#Random forest for Goodnight Moon


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


gdnt_mn_data_rf = sp_count_full[sp_count_full['Room'] == 'Goodnight Moon']

gdnt_mn_data_rf['hour'] = gdnt_mn_data_rf['Interval'].dt.hour
gdnt_mn_data_rf['year'] = gdnt_mn_data_rf['Interval'].dt.year
gdnt_mn_data_rf['month'] = gdnt_mn_data_rf['Interval'].dt.month
gdnt_mn_data_rf['day'] = gdnt_mn_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = gdnt_mn_data_rf[features]
Y = gdnt_mn_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_gdnt_mn
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_gdnt_mn = pd.DataFrame({'Interval': future_intervals})


future_data_rf_gdnt_mn['hour'] = future_data_rf_gdnt_mn['Interval'].dt.hour
future_data_rf_gdnt_mn['year'] = future_data_rf_gdnt_mn['Interval'].dt.year
future_data_rf_gdnt_mn['month'] = future_data_rf_gdnt_mn['Interval'].dt.month
future_data_rf_gdnt_mn['day'] = future_data_rf_gdnt_mn['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_gdnt_mn = fclf.predict(future_data_rf_gdnt_mn[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_gdnt_mn = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_gdnt_mn[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_gdnt_mn[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_gdnt_mn )

forecast_rf_gdnt_mn .to_csv("forecast_rf_gdnt_mn .csv", index=False)

#Random forest for Pandas


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


pnds_data_rf = sp_count_full[sp_count_full['Room'] == 'Pandas']

pnds_data_rf['hour'] = pnds_data_rf['Interval'].dt.hour
pnds_data_rf['year'] = pnds_data_rf['Interval'].dt.year
pnds_data_rf['month'] = pnds_data_rf['Interval'].dt.month
pnds_data_rf['day'] = pnds_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = pnds_data_rf[features]
Y = pnds_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_pnds
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_pnds = pd.DataFrame({'Interval': future_intervals})


future_data_rf_pnds['hour'] = future_data_rf_pnds['Interval'].dt.hour
future_data_rf_pnds['year'] = future_data_rf_pnds['Interval'].dt.year
future_data_rf_pnds['month'] = future_data_rf_pnds['Interval'].dt.month
future_data_rf_pnds['day'] = future_data_rf_pnds['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_pnds = fclf.predict(future_data_rf_pnds[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_pnds = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_pnds[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_pnds[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_pnds )

forecast_rf_pnds .to_csv("forecast_rf_pnds .csv", index=False)

#Random forest for Rabbits


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


rabts_data_rf = sp_count_full[sp_count_full['Room'] == 'Rabbits']

rabts_data_rf['hour'] = rabts_data_rf['Interval'].dt.hour
rabts_data_rf['year'] = rabts_data_rf['Interval'].dt.year
rabts_data_rf['month'] = rabts_data_rf['Interval'].dt.month
rabts_data_rf['day'] = rabts_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = rabts_data_rf[features]
Y = rabts_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_rabts
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_rabts = pd.DataFrame({'Interval': future_intervals})


future_data_rf_rabts['hour'] = future_data_rf_rabts['Interval'].dt.hour
future_data_rf_rabts['year'] = future_data_rf_rabts['Interval'].dt.year
future_data_rf_rabts['month'] = future_data_rf_rabts['Interval'].dt.month
future_data_rf_rabts['day'] = future_data_rf_rabts['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_rabts = fclf.predict(future_data_rf_rabts[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_rabts = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_rabts[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_rabts[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_rabts )

forecast_rf_rabts .to_csv("forecast_rf_rabts .csv", index=False)

#Random forest for Llamas Llamas


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


lama_data_rf = sp_count_full[sp_count_full['Room'] == 'Llamas Llamas']

lama_data_rf['hour'] = lama_data_rf['Interval'].dt.hour
lama_data_rf['year'] = lama_data_rf['Interval'].dt.year
lama_data_rf['month'] = lama_data_rf['Interval'].dt.month
lama_data_rf['day'] = lama_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = lama_data_rf[features]
Y = lama_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_lama
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_lama = pd.DataFrame({'Interval': future_intervals})


future_data_rf_lama['hour'] = future_data_rf_lama['Interval'].dt.hour
future_data_rf_lama['year'] = future_data_rf_lama['Interval'].dt.year
future_data_rf_lama['month'] = future_data_rf_lama['Interval'].dt.month
future_data_rf_lama['day'] = future_data_rf_lama['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_lama = fclf.predict(future_data_rf_lama[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_lama = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_lama[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_lama[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_lama )

forecast_rf_lama.to_csv("forecast_rf_lama.csv", index=False)

#Random forest for Hungry Caterpillars


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


hun_cat_data_rf = sp_count_full[sp_count_full['Room'] == 'Hungry Caterpillars']

hun_cat_data_rf['hour'] = hun_cat_data_rf['Interval'].dt.hour
hun_cat_data_rf['year'] = hun_cat_data_rf['Interval'].dt.year
hun_cat_data_rf['month'] = hun_cat_data_rf['Interval'].dt.month
hun_cat_data_rf['day'] = hun_cat_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = hun_cat_data_rf[features]
Y = hun_cat_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_hun_cat
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_hun_cat = pd.DataFrame({'Interval': future_intervals})


future_data_rf_hun_cat['hour'] = future_data_rf_hun_cat['Interval'].dt.hour
future_data_rf_hun_cat['year'] = future_data_rf_hun_cat['Interval'].dt.year
future_data_rf_hun_cat['month'] = future_data_rf_hun_cat['Interval'].dt.month
future_data_rf_hun_cat['day'] = future_data_rf_hun_cat['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_hun_cat = fclf.predict(future_data_rf_hun_cat[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_hun_cat = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_hun_cat[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_hun_cat[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_hun_cat )

forecast_rf_hun_cat.to_csv("forecast_rf_hun_cat.csv", index=False)

#Random forest for House Pooh


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


hos_ph_data_rf = sp_count_full[sp_count_full['Room'] == 'House Pooh']

hos_ph_data_rf['hour'] = hos_ph_data_rf['Interval'].dt.hour
hos_ph_data_rf['year'] = hos_ph_data_rf['Interval'].dt.year
hos_ph_data_rf['month'] = hos_ph_data_rf['Interval'].dt.month
hos_ph_data_rf['day'] = hos_ph_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = hos_ph_data_rf[features]
Y = hos_ph_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_hos_ph
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_hos_ph = pd.DataFrame({'Interval': future_intervals})


future_data_rf_hos_ph['hour'] = future_data_rf_hos_ph['Interval'].dt.hour
future_data_rf_hos_ph['year'] = future_data_rf_hos_ph['Interval'].dt.year
future_data_rf_hos_ph['month'] = future_data_rf_hos_ph['Interval'].dt.month
future_data_rf_hos_ph['day'] = future_data_rf_hos_ph['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_hos_ph = fclf.predict(future_data_rf_hos_ph[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_hos_ph = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_hos_ph[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_hos_ph[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_hos_ph )

forecast_rf_hos_ph.to_csv("forecast_rf_hos_ph.csv", index=False)