# -*- coding: utf-8 -*-
"""SpellmanModel(Complete).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xQ-0IfFD7Is23YyYwGCD0cyyqIa2jey7
"""

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "Spellman CDC 2022 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_22_df = raw_df.iloc[6:].copy()
sp_22_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_22_df = sp_22_df.loc[:, sp_22_df.columns.notnull()]
sp_22_df = sp_22_df.dropna(axis=1, how='all')

# Optional: Reset index
sp_22_df.reset_index(drop=True, inplace=True)
sp_22_df['Year'] = 2022
# Preview result
display(sp_22_df.head())
sp_22_df.to_csv("sp_full_dataset_22.csv", index=False)

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "Spellman CDC 2023 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_23_df = raw_df.iloc[6:].copy()
sp_23_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_23_df = sp_23_df.loc[:, sp_23_df.columns.notnull()]
sp_23_df = sp_23_df.dropna(axis=1, how='all')

# Reset index
sp_23_df.reset_index(drop=True, inplace=True)
sp_23_df['Year'] = 2023

# Preview result
display(sp_23_df.head())
sp_23_df.to_csv("sp_full_dataset_23.csv", index=False)

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "Spellman CDC 2024 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_24_df = raw_df.iloc[6:].copy()
sp_24_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_24_df = sp_24_df.loc[:, sp_24_df.columns.notnull()]
sp_24_df = sp_24_df.dropna(axis=1, how='all')

# Optional: Reset index
sp_24_df.reset_index(drop=True, inplace=True)
sp_24_df['Year'] = 2024

# Preview result
display(sp_24_df.head())
sp_24_df.to_csv("sp_full_dataset_24.csv", index=False)

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "Spellman CDC 2025 01012025-02282025 Student Sign in and out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 : Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
sp_25_df = raw_df.iloc[6:].copy()
sp_25_df.columns = new_columns

# Step 5: Drop completely empty columns
sp_25_df = sp_25_df.loc[:, sp_25_df.columns.notnull()]
sp_25_df = sp_25_df.dropna(axis=1, how='all')

# Optional: Reset index
sp_25_df.reset_index(drop=True, inplace=True)
sp_25_df['Year'] = 2025

# Preview result
display(sp_25_df.head())
sp_25_df.to_csv("sp_full_dataset.csv", index=False)

#check for duplicates
print("Duplicate columns in sp_22_df:", sp_22_df.columns[sp_22_df.columns.duplicated()])
print("Duplicate columns in sp_23_df:", sp_23_df.columns[sp_23_df.columns.duplicated()])
print("Duplicate columns in sp_24_df:", sp_24_df.columns[sp_24_df.columns.duplicated()])
print("Duplicate columns in sp_25_df:", sp_25_df.columns[sp_25_df.columns.duplicated()])

# Concatenate all cleaned DataFrames into one
sp = pd.concat([sp_22_df, sp_23_df, sp_24_df, sp_25_df], axis=0, ignore_index=True)

# Reorder columns by month
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

# Separate the first 5 columns
first_columns = sp.columns[:4].tolist()

# Identify month-related columns (after the first 5 columns)
month_columns = [col for col in sp.columns[4:] if any(col.startswith(month) for month in month_order)]
other_columns = [col for col in sp.columns[4:] if col not in month_columns]

# Sort month columns by month order
sorted_month_columns = sorted(month_columns, key=lambda col: (month_order.index(col[:3]), col))

# Combine the first 5 columns, sorted month columns, and other columns
sp_time = sp[first_columns + sorted_month_columns + other_columns]

#Replace all Nan with 0s
sp_time = sp_time.fillna(0)

#commneted this out because dont want this, need text to stay in these columns# Convert month-related columns to binomial code
#for col in sorted_month_columns:
 #   if "IN" in col:
    #    sp[col] = sp[col].apply(lambda x: 1 if pd.notna(x) else 0)  # 1 for check-in
  #  elif "OUT" in col:
   #     sp[col] = sp[col].apply(lambda x: 2 if pd.notna(x) else 0)  # 2 for check-out

# Display the cleaned and transformed DataFrame
print("Cleaned and Transformed Combined DataFrame Preview:")
display(sp_time)

# Export the transformed DataFrame to a CSV file
sp_time.to_csv("combined_sp_time.csv", index=False)

# drop _OUT columns (created a seperate datafram without the out columns) this for Time sp dataframe
sp_in_time = sp_time.loc[:, ~sp_time.columns.str.endswith('_OUT')]
# reset index
sp_in_time.reset_index(drop=True, inplace=True)
#save to csv
sp_in_time.to_csv("combined_sp_binomial_no_out_time.csv", index=False)

display(sp_in_time)

# drop _IN columns (created a seperate datafram without the in columns)
sp_out_time = sp_time.loc[:, ~sp_time.columns.str.endswith('_IN')]
# reset index
sp_out_time.reset_index(drop=True, inplace=True)
#save to csv
sp_out_time.to_csv("combined_sp_binomial_no_in_time.csv", index=False)

#now will further condense/ clean data with only IN columns (for columns with times)
#STARTING WITH TIME IN DATA
import pandas as pd

metadata_columns = ['Record ID', 'Student Status', 'Room', 'Tags', 'Year']  # Include 'Year' in metadata

# Identify date columns (columns with month names)
date_columns = [col for col in sp_in_time.columns if any(month in col for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                                                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])]

# Melt the DataFrame to create a long format
sp_long_in_time = sp_in_time.melt(id_vars=metadata_columns,
                            value_vars=date_columns,
                            var_name='Date_Event',
                            value_name='Time_IN')



# Split 'Date_Event' into 'Month Day' and 'Event' (e.g., Jan 02 and IN)
sp_long_in_time[['Month_Day', 'Event_IN']] = sp_long_in_time['Date_Event'].str.rsplit('_', n=1, expand=True)

# Clean 'Month_Day' string and construct the full date
sp_long_in_time['Month_Day'] = sp_long_in_time['Month_Day'].str.strip()
date_strings = sp_long_in_time['Month_Day'] + " " + sp_long_in_time['Year'].astype(str)
sp_long_in_time['Date'] = pd.to_datetime(date_strings, format='%b %d %Y', errors='coerce')

# Drop rows with invalid dates or zero values
sp_long_in_time = sp_long_in_time[(~sp_long_in_time['Date'].isna()) & (sp_long_in_time['Time_IN'] != 0)]

# Drop temporary columns
sp_long_in_time.drop(columns=['Date_Event', 'Month_Day', 'Year'], inplace=True)



# Reset the index
sp_long_in_time.reset_index(drop=True, inplace=True)

# Preview the reshaped DataFrame
display(sp_long_in_time.head())

# Save the reshaped DataFrame to a CSV file
sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)

#now will further condense/ clean data with only OUT columns (for columns with times)
import pandas as pd

metadata_columns = ['Record ID', 'Student Status', 'Room', 'Tags', 'Year']  # Include 'Year' in metadata

# Identify date columns (columns with month names)
date_columns = [col for col in sp_out_time.columns if any(month in col for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                                                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])]

# Melt the DataFrame to create a long format
sp_long_out_time = sp_out_time.melt(id_vars=metadata_columns,
                            value_vars=date_columns,
                            var_name='Date_Event',
                            value_name='Time_OUT')


# Split 'Date_Event' into 'Month Day' and 'Event' (e.g., Jan 02 and IN)
sp_long_out_time[['Month_Day', 'Event_OUT']] =sp_long_out_time['Date_Event'].str.rsplit('_', n=1, expand=True)

# Clean 'Month_Day' string and construct the full date
sp_long_out_time['Month_Day'] = sp_long_out_time['Month_Day'].str.strip()
date_strings = sp_long_out_time['Month_Day'] + " " + sp_long_out_time['Year'].astype(str)
sp_long_out_time['Date'] = pd.to_datetime(date_strings, format='%b %d %Y', errors='coerce')

# Drop rows with invalid dates or zero values
sp_long_out_time = sp_long_out_time[(~sp_long_out_time['Date'].isna()) & (sp_long_out_time['Time_OUT'] != 0)]

# Drop temporary columns
sp_long_out_time.drop(columns=['Date_Event', 'Month_Day', 'Year'], inplace=True)



# Reset the index
sp_long_out_time.reset_index(drop=True, inplace=True)

# Preview the reshaped DataFrame
display(sp_long_out_time.head())

# Save the reshaped DataFrame to a CSV file
sp_long_out_time.to_csv("sp_long_out_time_format.csv", index=False)

#Now going to pop the out column from sp_long_out so that we can then add it to the sp_long_in data set
import pandas

#taking out the event out column because it is redundant (removing from sp_long_out_time )
#remove_event_out = sp_long_out_time.pop('Event_OUT')

#taking out the event out column because it is redundant (removing from sp_long_in_time )
#remove_event_in = sp_long_in_time.pop('Event_IN')

#taking out the time out column because this is the one we want to add to the other dataframe
remove_time_out = sp_long_out_time.pop('Time_OUT')

display(sp_long_out_time.head())

#now going to add the removed column Time_OUT to the sp_long_in_time dataframe
sp_long_in_time['Time_OUT'] = remove_time_out

#display newly added colum in the dataframe
display(sp_long_in_time.head())

#going to reset the values of the dataframe for sp long time in for better readabilty

# State the colum order wanted
desired_column_order = ['Record ID', 'Student Status', 'Room', 'Tags', 'Time_IN', 'Time_OUT', 'Date']

# Reorder columns by setting equal to orignal data frame
sp_long_in_time = sp_long_in_time[desired_column_order]

# Display the DataFrame with reordered columns
display(sp_long_in_time.head())

#save new format to csv file
sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)

#now going to extract the times from the Time_In and Time_Out

import pandas as pd
import re
from dateutil.parser import parse

def extract_time(text):
    match = re.search(r'(\d{1,2}:\d{2} (?:AM|PM))', str(text))
    if match:
        return match.group(1)
    else:
        return None

#apply function to date frame columns to extract time
sp_long_in_time['Time_IN'] = sp_long_in_time['Time_IN'].apply(extract_time)
sp_long_in_time['Time_OUT'] = sp_long_in_time['Time_OUT'].apply(extract_time)

#display times only in data frame
display(sp_long_in_time.head())

from datetime import datetime, timedelta
#check data type for all columns, just to see what is already a datetime
print(sp_long_in_time.dtypes)

#now going to combine the date and time columns together and then convert them into date time objects

display(sp_long_in_time.head())

#convert time component from 'Time_IN' and 'Time_OUT' to datetime.time
#replace nat values  with a default time (00:00:00)
default_time = datetime.min.time()  # or any other desired default time
sp_long_in_time['Time_IN'] = pd.to_datetime(sp_long_in_time['Time_IN']).dt.time.fillna(default_time)

sp_long_in_time['Time_OUT'] = pd.to_datetime(sp_long_in_time['Time_OUT']).dt.time.fillna(default_time)

#convert column to datetime.date if it's a Timestamp
sp_long_in_time['Date'] = pd.to_datetime(sp_long_in_time['Date']).dt.date

print(sp_long_in_time.dtypes)

#now going to combine the date and time columns together and then convert them into date time objects

from datetime import datetime
#check data type for all columns
print(sp_long_in_time.dtypes)





# datetime.combine
sp_long_in_time['Time_IN'] = sp_long_in_time.apply(lambda row: datetime.combine(row['Date'], row['Time_IN']), axis=1)
sp_long_in_time['Time_OUT'] = sp_long_in_time.apply(lambda row: datetime.combine(row['Date'], row['Time_OUT']), axis=1)

display(sp_long_in_time.head())



sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)


#DO NOT DELETE THE DATE COLUMN!!! LEAVE IT

#now sort the dataframe by date (earliest)
sp_long_in_time = sp_long_in_time.sort_values(by=['Time_IN'])

display(sp_long_in_time.head())

#save to csv
sp_long_in_time.to_csv("sp_long_in_time_format.csv", index=False)

#Find all of the unique room names included on data frame
unique_rooms = sp_long_in_time['Room'].unique()
print(unique_rooms)

#Starting with sp data going to create new dataframes for each Room

#Start with Room for Dinosaur Stomp

#create new dataframe to filter out only prek-k1 entries
dino_stmp_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Dinosaur Stomp']

#display new dataframe
display(dino_stmp_sp.head())

#save new data frame to a csv
dino_stmp_sp.to_csv("dino_stmp_sp.csv", index=False)

#determine daily student count in 30 minute intervals
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=dino_stmp_sp['Time_IN'].min().floor('30min'),
                          end=dino_stmp_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = dino_stmp_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (dino_stmp_sp['Time_IN'] <= end) & (dino_stmp_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Dinosaur Stomp', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
dino_stmp_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(dino_stmp_sp_30min_counts)

#save to csv
dino_stmp_sp_30min_counts.to_csv("dino_stmp_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#prek ratio is 12 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 12:
        return 1  # 1 staff member for up to 12 students
    elif student_count <= 24:
        return 2  # 2 staff members for 13-24 students
    elif student_count <= 36:
        return 3  # 3 staff members for 25-36 students
    elif student_count <= 48:
        return 4  # 4 staff members for 37-48 students
    else:
        return "Error: count ratio not accounted for"

# create the 'Staffing Needs' column with funcyion
dino_stmp_sp_30min_counts['Staffing Needs'] = dino_stmp_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(dino_stmp_sp_30min_counts)

#save to csv
dino_stmp_sp_30min_counts.to_csv("dino_stmp_sp_30min_counts.csv", index=False)

#create data frame for Wild Things

#create new dataframe to filter out entries
wild_th_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Wild Things']

#display new dataframe
display(wild_th_sp.head())

#save new data frame to a csv
wild_th_sp.to_csv("wild_th_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# 30 min time interval based on time and time out columns
time_range = pd.date_range(start=wild_th_sp['Time_IN'].min().floor('30min'),
                          end=wild_th_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = wild_th_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (wild_th_sp['Time_IN'] <= end) & (wild_th_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Wild Things', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
wild_th_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(wild_th_sp_30min_counts)

#save to csv
wild_th_sp_30min_counts.to_csv("wild_th_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#preschool ratio is 10 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 10:
        return 1  # 1 staff member for up to 10 students
    elif student_count <= 20:
        return 2  # 2 staff members for 11-20 students
    elif student_count <= 30:
        return 3  # 3 staff members for 21-30 students
    elif student_count <= 40:
        return 4  # 4 staff members for 31-40 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
wild_th_sp_30min_counts['Staffing Needs'] = wild_th_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(wild_th_sp_30min_counts)

#save to csv
wild_th_sp_30min_counts.to_csv("wild_th_sp_30min_counts.csv", index=False)

#create data frame for Monkeys

#create new dataframe to filter out entries
monk_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Monkeys']

#display new dataframe
display(monk_sp.head())

#save new data frame to a csv
monk_sp.to_csv("monk_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=monk_sp['Time_IN'].min().floor('30min'),
                          end=monk_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = monk_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (monk_sp['Time_IN'] <= end) & (monk_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Monkeys', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

monk_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(monk_sp_30min_counts)

#save to csv
monk_sp_30min_counts.to_csv("monk_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Toddler ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
monk_sp_30min_counts['Staffing Needs'] = monk_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(monk_sp_30min_counts)

#save to csv
monk_sp_30min_counts.to_csv("monk_sp_30min_counts.csv", index=False)

#Starting with sp data going to create new dataframes for each Room

#Start with Room for Rainbow Fish

#create new dataframe to filter out only prek-k1 entries
rain_fs_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Rainbow Fish']

#display new dataframe
display(rain_fs_sp.head())

#save new data frame to a csv
rain_fs_sp.to_csv("rain_fs_sp.csv", index=False)

#determine daily student count in 30 minute intervals
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=rain_fs_sp['Time_IN'].min().floor('30min'),
                          end=rain_fs_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = rain_fs_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (rain_fs_sp['Time_IN'] <= end) & (rain_fs_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Rainbow Fish', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
rain_fs_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(rain_fs_sp_30min_counts)

#save to csv
rain_fs_sp_30min_counts.to_csv("rain_fs_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#preschool ratio is 10 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 10:
        return 1  # 1 staff member for up to 10 students
    elif student_count <= 20:
        return 2  # 2 staff members for 11-20 students
    elif student_count <= 30:
        return 3  # 3 staff members for 21-30 students
    elif student_count <= 40:
        return 4  # 4 staff members for 31-40 students
    else:
        return "Error: count ratio not accounted for"

# create the 'Staffing Needs' column with funcyion
rain_fs_sp_30min_counts['Staffing Needs'] = rain_fs_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(rain_fs_sp_30min_counts)

#save to csv
rain_fs_sp_30min_counts.to_csv("rain_fs_sp_30min_counts.csv", index=False)

#create data frame for Goodnight Moon

#create new dataframe to filter out entries
gdnt_mn_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Goodnight Moon']

#display new dataframe
display(gdnt_mn_sp.head())

#save new data frame to a csv
gdnt_mn_sp.to_csv("gdnt_mn_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = gdnt_mn_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (gdnt_mn_sp['Time_IN'] <= end) & (gdnt_mn_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Goodnight Moon', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

gdnt_mn_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(gdnt_mn_sp_30min_counts)

#save to csv
gdnt_mn_sp_30min_counts.to_csv("gdnt_mn_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Infant ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
gdnt_mn_sp_30min_counts['Staffing Needs'] = gdnt_mn_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(gdnt_mn_sp_30min_counts)

#save to csv
gdnt_mn_sp_30min_counts.to_csv("gdnt_mn_sp_30min_counts.csv", index=False)

#create data frame for Pandas

#create new dataframe to filter out entries
pnds_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Pandas']

#display new dataframe
display(pnds_sp.head())

#save new data frame to a csv
pnds_sp.to_csv("pnds_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=pnds_sp['Time_IN'].min().floor('30min'),
                          end=pnds_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = pnds_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (pnds_sp['Time_IN'] <= end) & (pnds_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Pandas', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

pnds_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(pnds_sp_30min_counts)

#save to csv
pnds_sp_30min_counts.to_csv("pnds_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#toddler have 6:1 ratio

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
pnds_sp_30min_counts['Staffing Needs'] = pnds_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(pnds_sp_30min_counts)

#save to csv
pnds_sp_30min_counts.to_csv("pnds_sp_30min_counts.csv", index=False)

#create data frame for Rabbits

#create new dataframe to filter out entries
rabts_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Rabbits']

#display new dataframe
display(rabts_sp.head())

#save new data frame to a csv
rabts_sp.to_csv("rabts_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=rabts_sp['Time_IN'].min().floor('30min'),
                          end=rabts_sp['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = rabts_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (rabts_sp['Time_IN'] <= end) & (rabts_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Rabbits', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

rabts_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(rabts_sp_30min_counts)

#save to csv
rabts_sp_30min_counts.to_csv("rabts_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#toddler have 6:1 ratio

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
rabts_sp_30min_counts['Staffing Needs'] = rabts_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(rabts_sp_30min_counts)

#save to csv
rabts_sp_30min_counts.to_csv("rabts_sp_30min_counts.csv", index=False)

#create data frame for Llamas Llamas

#create new dataframe to filter out entries
lama_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Llamas Llamas']

#display new dataframe
display(lama_sp.head())

#save new data frame to a csv
lama_sp.to_csv("lama_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = lama_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (lama_sp['Time_IN'] <= end) & (lama_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Llamas Llamas', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

lama_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(lama_sp_30min_counts)

#save to csv
lama_sp_30min_counts.to_csv("lama_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Multi Age ratio is 4 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 4:
        return 1  # 1 staff member for up to 4 students
    elif student_count <= 8:
        return 2  # 2 staff members for 5-8 students
    elif student_count <= 12:
        return 3  # 3 staff members for 9-12 students
    elif student_count <= 16:
        return 4  # 4 staff members for 13-16 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
lama_sp_30min_counts['Staffing Needs'] = lama_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(lama_sp_30min_counts)

#save to csv
lama_sp_30min_counts.to_csv("lama_sp_30min_counts.csv", index=False)

#create data frame for Hungry Caterpillars

#create new dataframe to filter out entries
hun_cat_sp = sp_long_in_time[sp_long_in_time['Room'] == 'Hungry Caterpillars']

#display new dataframe
display(hun_cat_sp.head())

#save new data frame to a csv
hun_cat_sp.to_csv("hun_cat_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = hun_cat_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (hun_cat_sp['Time_IN'] <= end) & (hun_cat_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Hungry Caterpillars', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))

#make a new data frame, with new variable interval that will hold the 30 mins at each start time
#gramp_pre_sp_30min_counts = pd.DataFrame({'Interval': time_range[:-1], 'Count': counts})
#now I can call on the data frame in a cool way

hun_cat_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(hun_cat_sp_30min_counts)

#save to csv
hun_cat_sp_30min_counts.to_csv("hun_cat_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Multi Age ratio is 4 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 4:
        return 1  # 1 staff member for up to 4 students
    elif student_count <= 8:
        return 2  # 2 staff members for 5-8 students
    elif student_count <= 12:
        return 3  # 3 staff members for 9-12 students
    elif student_count <= 16:
        return 4  # 4 staff members for 13-16 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
hun_cat_sp_30min_counts['Staffing Needs'] = hun_cat_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(hun_cat_sp_30min_counts)

#save to csv
hun_cat_sp_30min_counts.to_csv("hun_cat_sp_30min_counts.csv", index=False)

#create data frame for House Pooh

#create new dataframe to filter out entries
hos_ph_sp = sp_long_in_time[sp_long_in_time['Room'] == 'House Pooh']

#display new dataframe
display(hos_ph_sp.head())

#save new data frame to a csv
hos_ph_sp.to_csv("hos_ph_sp.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = hos_ph_sp[ #trying to modify code so that it will keep the Room column in final dataframe
      (hos_ph_sp['Time_IN'] <= end) & (hos_ph_sp['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'House Pooh', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

hos_ph_sp_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(hos_ph_sp_30min_counts)

#save to csv
hos_ph_sp_30min_counts.to_csv("hos_ph_sp_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Infant ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
hos_ph_sp_30min_counts['Staffing Needs'] = hos_ph_sp_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(hos_ph_sp_30min_counts)

#save to csv
hos_ph_sp_30min_counts.to_csv("hos_ph_sp_30min_counts.csv", index=False)

#now going to combine all 30 minute dataframes with the counts, into 1 data frame

sp_count_full = pd.concat([dino_stmp_sp_30min_counts, rain_fs_sp_30min_counts, wild_th_sp_30min_counts, monk_sp_30min_counts, gdnt_mn_sp_30min_counts, pnds_sp_30min_counts, rabts_sp_30min_counts, lama_sp_30min_counts, hun_cat_sp_30min_counts, hos_ph_sp_30min_counts  ])

display(sp_count_full)

#save to csv
sp_count_full.to_csv("sp_count_full.csv", index=False)

"""Next: Create the Random forests for each room and create the forecasts"""

#Random forest for Dinosaur Stomp


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


dino_stmp_data_rf = sp_count_full[sp_count_full['Room'] == 'Dinosaur Stomp']

dino_stmp_data_rf['hour'] = dino_stmp_data_rf['Interval'].dt.hour
dino_stmp_data_rf['year'] = dino_stmp_data_rf['Interval'].dt.year
dino_stmp_data_rf['month'] = dino_stmp_data_rf['Interval'].dt.month
dino_stmp_data_rf['day'] = dino_stmp_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = dino_stmp_data_rf[features]
Y = dino_stmp_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_dino_stmp
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_dino_stmp = pd.DataFrame({'Interval': future_intervals})


future_data_rf_dino_stmp['hour'] = future_data_rf_dino_stmp['Interval'].dt.hour
future_data_rf_dino_stmp['year'] = future_data_rf_dino_stmp['Interval'].dt.year
future_data_rf_dino_stmp['month'] = future_data_rf_dino_stmp['Interval'].dt.month
future_data_rf_dino_stmp['day'] = future_data_rf_dino_stmp['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_dino_stmp = fclf.predict(future_data_rf_dino_stmp[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_dino_stmp = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_dino_stmp[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_dino_stmp[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_dino_stmp )

forecast_rf_dino_stmp .to_csv("forecast_rf_dino_stmp .csv", index=False)

#Random forest for Rainbow Fish


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


rain_fs_data_rf = sp_count_full[sp_count_full['Room'] == 'Rainbow Fish']

rain_fs_data_rf['hour'] = rain_fs_data_rf['Interval'].dt.hour
rain_fs_data_rf['year'] = rain_fs_data_rf['Interval'].dt.year
rain_fs_data_rf['month'] = rain_fs_data_rf['Interval'].dt.month
rain_fs_data_rf['day'] = rain_fs_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = rain_fs_data_rf[features]
Y = rain_fs_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo



#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_rain_fs
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_rain_fs = pd.DataFrame({'Interval': future_intervals})


future_data_rf_rain_fs['hour'] = future_data_rf_rain_fs['Interval'].dt.hour
future_data_rf_rain_fs['year'] = future_data_rf_rain_fs['Interval'].dt.year
future_data_rf_rain_fs['month'] = future_data_rf_rain_fs['Interval'].dt.month
future_data_rf_rain_fs['day'] = future_data_rf_rain_fs['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_rain_fs = fclf.predict(future_data_rf_rain_fs[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_rain_fs = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_rain_fs[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_rain_fs[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_rain_fs )

forecast_rf_rain_fs .to_csv("forecast_rf_rain_fs .csv", index=False)

#Random forest for Wild Things


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


wild_th_data_rf = sp_count_full[sp_count_full['Room'] == 'Wild Things']

wild_th_data_rf['hour'] = wild_th_data_rf['Interval'].dt.hour
wild_th_data_rf['year'] = wild_th_data_rf['Interval'].dt.year
wild_th_data_rf['month'] = wild_th_data_rf['Interval'].dt.month
wild_th_data_rf['day'] = wild_th_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = wild_th_data_rf[features]
Y = wild_th_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_wild_th
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_wild_th = pd.DataFrame({'Interval': future_intervals})


future_data_rf_wild_th['hour'] = future_data_rf_wild_th['Interval'].dt.hour
future_data_rf_wild_th['year'] = future_data_rf_wild_th['Interval'].dt.year
future_data_rf_wild_th['month'] = future_data_rf_wild_th['Interval'].dt.month
future_data_rf_wild_th['day'] = future_data_rf_wild_th['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_wild_th = fclf.predict(future_data_rf_wild_th[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_wild_th = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_wild_th[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_wild_th[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_wild_th )

forecast_rf_wild_th .to_csv("forecast_rf_wild_th .csv", index=False)

#Random forest for Monkeys


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


monk_data_rf = sp_count_full[sp_count_full['Room'] == 'Monkeys']

monk_data_rf['hour'] = monk_data_rf['Interval'].dt.hour
monk_data_rf['year'] = monk_data_rf['Interval'].dt.year
monk_data_rf['month'] = monk_data_rf['Interval'].dt.month
monk_data_rf['day'] = monk_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = monk_data_rf[features]
Y = monk_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_monk
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_monk = pd.DataFrame({'Interval': future_intervals})


future_data_rf_monk['hour'] = future_data_rf_monk['Interval'].dt.hour
future_data_rf_monk['year'] = future_data_rf_monk['Interval'].dt.year
future_data_rf_monk['month'] = future_data_rf_monk['Interval'].dt.month
future_data_rf_monk['day'] = future_data_rf_monk['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_monk = fclf.predict(future_data_rf_monk[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_monk = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_monk[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_monk[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_monk )

forecast_rf_monk .to_csv("forecast_rf_monk .csv", index=False)

#Random forest for Goodnight Moon


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


gdnt_mn_data_rf = sp_count_full[sp_count_full['Room'] == 'Goodnight Moon']

gdnt_mn_data_rf['hour'] = gdnt_mn_data_rf['Interval'].dt.hour
gdnt_mn_data_rf['year'] = gdnt_mn_data_rf['Interval'].dt.year
gdnt_mn_data_rf['month'] = gdnt_mn_data_rf['Interval'].dt.month
gdnt_mn_data_rf['day'] = gdnt_mn_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = gdnt_mn_data_rf[features]
Y = gdnt_mn_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_gdnt_mn
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_gdnt_mn = pd.DataFrame({'Interval': future_intervals})


future_data_rf_gdnt_mn['hour'] = future_data_rf_gdnt_mn['Interval'].dt.hour
future_data_rf_gdnt_mn['year'] = future_data_rf_gdnt_mn['Interval'].dt.year
future_data_rf_gdnt_mn['month'] = future_data_rf_gdnt_mn['Interval'].dt.month
future_data_rf_gdnt_mn['day'] = future_data_rf_gdnt_mn['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_gdnt_mn = fclf.predict(future_data_rf_gdnt_mn[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_gdnt_mn = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_gdnt_mn[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_gdnt_mn[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_gdnt_mn )

forecast_rf_gdnt_mn .to_csv("forecast_rf_gdnt_mn .csv", index=False)

#Random forest for Pandas


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


pnds_data_rf = sp_count_full[sp_count_full['Room'] == 'Pandas']

pnds_data_rf['hour'] = pnds_data_rf['Interval'].dt.hour
pnds_data_rf['year'] = pnds_data_rf['Interval'].dt.year
pnds_data_rf['month'] = pnds_data_rf['Interval'].dt.month
pnds_data_rf['day'] = pnds_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = pnds_data_rf[features]
Y = pnds_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_pnds
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_pnds = pd.DataFrame({'Interval': future_intervals})


future_data_rf_pnds['hour'] = future_data_rf_pnds['Interval'].dt.hour
future_data_rf_pnds['year'] = future_data_rf_pnds['Interval'].dt.year
future_data_rf_pnds['month'] = future_data_rf_pnds['Interval'].dt.month
future_data_rf_pnds['day'] = future_data_rf_pnds['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_pnds = fclf.predict(future_data_rf_pnds[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_pnds = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_pnds[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_pnds[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_pnds )

forecast_rf_pnds .to_csv("forecast_rf_pnds .csv", index=False)

#Random forest for Rabbits


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


rabts_data_rf = sp_count_full[sp_count_full['Room'] == 'Rabbits']

rabts_data_rf['hour'] = rabts_data_rf['Interval'].dt.hour
rabts_data_rf['year'] = rabts_data_rf['Interval'].dt.year
rabts_data_rf['month'] = rabts_data_rf['Interval'].dt.month
rabts_data_rf['day'] = rabts_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = rabts_data_rf[features]
Y = rabts_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times for rforecast
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_rabts
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_rabts = pd.DataFrame({'Interval': future_intervals})


future_data_rf_rabts['hour'] = future_data_rf_rabts['Interval'].dt.hour
future_data_rf_rabts['year'] = future_data_rf_rabts['Interval'].dt.year
future_data_rf_rabts['month'] = future_data_rf_rabts['Interval'].dt.month
future_data_rf_rabts['day'] = future_data_rf_rabts['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_rabts = fclf.predict(future_data_rf_rabts[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_rabts = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_rabts[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_rabts[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_rabts )

forecast_rf_rabts .to_csv("forecast_rf_rabts .csv", index=False)

#Random forest for Llamas Llamas


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


lama_data_rf = sp_count_full[sp_count_full['Room'] == 'Llamas Llamas']

lama_data_rf['hour'] = lama_data_rf['Interval'].dt.hour
lama_data_rf['year'] = lama_data_rf['Interval'].dt.year
lama_data_rf['month'] = lama_data_rf['Interval'].dt.month
lama_data_rf['day'] = lama_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = lama_data_rf[features]
Y = lama_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_lama
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_lama = pd.DataFrame({'Interval': future_intervals})


future_data_rf_lama['hour'] = future_data_rf_lama['Interval'].dt.hour
future_data_rf_lama['year'] = future_data_rf_lama['Interval'].dt.year
future_data_rf_lama['month'] = future_data_rf_lama['Interval'].dt.month
future_data_rf_lama['day'] = future_data_rf_lama['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_lama = fclf.predict(future_data_rf_lama[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_lama = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_lama[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_lama[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_lama )

forecast_rf_lama.to_csv("forecast_rf_lama.csv", index=False)

#Random forest for Hungry Caterpillars


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


hun_cat_data_rf = sp_count_full[sp_count_full['Room'] == 'Hungry Caterpillars']

hun_cat_data_rf['hour'] = hun_cat_data_rf['Interval'].dt.hour
hun_cat_data_rf['year'] = hun_cat_data_rf['Interval'].dt.year
hun_cat_data_rf['month'] = hun_cat_data_rf['Interval'].dt.month
hun_cat_data_rf['day'] = hun_cat_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = hun_cat_data_rf[features]
Y = hun_cat_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_hun_cat
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_hun_cat = pd.DataFrame({'Interval': future_intervals})


future_data_rf_hun_cat['hour'] = future_data_rf_hun_cat['Interval'].dt.hour
future_data_rf_hun_cat['year'] = future_data_rf_hun_cat['Interval'].dt.year
future_data_rf_hun_cat['month'] = future_data_rf_hun_cat['Interval'].dt.month
future_data_rf_hun_cat['day'] = future_data_rf_hun_cat['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_hun_cat = fclf.predict(future_data_rf_hun_cat[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_hun_cat = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_hun_cat[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_hun_cat[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_hun_cat )

forecast_rf_hun_cat.to_csv("forecast_rf_hun_cat.csv", index=False)

#Random forest for House Pooh


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score


hos_ph_data_rf = sp_count_full[sp_count_full['Room'] == 'House Pooh']

hos_ph_data_rf['hour'] = hos_ph_data_rf['Interval'].dt.hour
hos_ph_data_rf['year'] = hos_ph_data_rf['Interval'].dt.year
hos_ph_data_rf['month'] = hos_ph_data_rf['Interval'].dt.month
hos_ph_data_rf['day'] = hos_ph_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = hos_ph_data_rf[features]
Y = hos_ph_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 30% for testing and 70% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student count-Regression
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

#staffing needs-classification
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
#calculate rsquared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_hos_ph
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_hos_ph = pd.DataFrame({'Interval': future_intervals})


future_data_rf_hos_ph['hour'] = future_data_rf_hos_ph['Interval'].dt.hour
future_data_rf_hos_ph['year'] = future_data_rf_hos_ph['Interval'].dt.year
future_data_rf_hos_ph['month'] = future_data_rf_hos_ph['Interval'].dt.month
future_data_rf_hos_ph['day'] = future_data_rf_hos_ph['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_hos_ph = fclf.predict(future_data_rf_hos_ph[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_hos_ph = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_hos_ph[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_hos_ph[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_hos_ph )

forecast_rf_hos_ph.to_csv("forecast_rf_hos_ph.csv", index=False)

#now going to add together each rooms forecast to make a total forecast
import pandas as pd
all_room_forecasts_rf_sp = pd.concat([forecast_rf_rabts, forecast_rf_lama, forecast_rf_hun_cat, forecast_rf_hos_ph, forecast_rf_pnds, forecast_rf_gdnt_mn, forecast_rf_monk, forecast_rf_wild_th, forecast_rf_rain_fs, forecast_rf_dino_stmp], ignore_index=True)

#now group them all by the intercal term and calculate the total student count and staffing needs
#also reset index so interval is column
total_forecasts_rf_sp = all_room_forecasts_rf_sp.groupby('Interval').agg({'Predicted Student Count': 'sum', 'Predicted Staffing Needs': 'sum'}).reset_index()

#display results
display(total_forecasts_rf_sp)

#save to csv
total_forecasts_rf_sp.to_csv("total_forecasts_rf_sp.csv", index=False)

#now get the Total sum for each day of the predicted week
#create a day column and remove it as datetime from interval
#this is giving the the total students in every 30 minute interval
# i dont think this necessarily a helpful stat
total_forecasts_rf_sp['Day'] = total_forecasts_rf_sp['Interval'].dt.day_name()
day_total_forecasts_rf_sp = total_forecasts_rf_sp.groupby('Day').agg({'Predicted Student Count': 'sum', 'Predicted Staffing Needs': 'sum'}).reset_index()
display(day_total_forecasts_rf_sp)

#calcualte average student count and staffing
 #(this would be an 7 day average, including the weekend on 3/1 and 3/2 )
 #this average also includes non working hours (where the student count and staff are 0)
 #would be helpful if we had data on the exact hours of the facilty so we can tweek the average to fit in those hours
 #instead we can just get remove any 0 entries

 #average for 7 day week, including non work hours (where staff and student 0)
 #so this is the average student count every 30 minutes
#need to remove
average_forecasts_rf_sp_7 = total_forecasts_rf_sp.agg({'Predicted Student Count': 'mean', 'Predicted Staffing Needs': 'mean'})

display(average_forecasts_rf_sp_7)

#save to csv
average_forecasts_rf_sp_7.to_csv("average_forecasts_rf_sp.csv_7", index=False)

#grab unforecasted data that has all student counts and staffing needs
total_sp_count_full = pd.read_csv("sp_count_full.csv")

display(total_sp_count_full)

#convert interval to dt object
total_sp_count_full['Interval'] = pd.to_datetime(total_sp_count_full['Interval'])

#get total over all dates/intervals
total_sp_count_full = total_sp_count_full.groupby('Interval').agg({'Count': 'sum', 'Staffing Needs': 'sum'}).reset_index()

display(total_sp_count_full)

#save as csv (this what we use for prophet)
total_sp_count_full.to_csv("total_sp_count_full.csv", index=False)

#get total by week day
#now add together total counts across all classrooms for each day
day_total_sp_count_full = pd.read_csv("sp_count_full.csv")
day_total_sp_count_full['Day'] = total_sp_count_full['Interval'].dt.day_name()
day_total_sp_count_full = day_total_sp_count_full.groupby('Day').agg({'Count': 'sum', 'Staffing Needs': 'sum'}).reset_index()

display(day_total_sp_count_full)

day_total_sp_count_full.to_csv("day_total_sp_count_full.csv", index=False)

#Prophet forecast for Pennie Preschool
import pandas as pd
import numpy as np
from prophet import Prophet
import matplotlib.pyplot as plt


# Read in data, (filter out  data from combined dataset)
total_count_sp_data_proph= pd.read_csv("total_sp_count_full.csv")

#keep only the dates and y vlaues
total_count_sp_data_proph = total_count_sp_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
total_count_sp_data_proph = pd.DataFrame(total_count_sp_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

total_count_sp_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

total_count_sp_model_proph.fit(total_count_sp_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_total_count_sp = total_count_sp_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
total_count_sp_forecast_proph = total_count_sp_model_proph.predict(future_total_count_sp)

total_count_sp_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecastProph_week_total_count_sp = total_count_sp_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecastProph_week_total_count_sp)

#looking at this dataframe while prophet is able to capture teh staffing trends, as far as actaul counts it is very off, even has negatives!
final_forecastProph_week_total_count_sp.to_csv("final_forecastProph_week_total_count_sp.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_total_count_sp_proph =  total_count_sp_model_proph.plot(total_count_sp_forecast_proph)
fig_total_count_sp_proph.show()
plt.savefig("total_count_sp_proph.png")

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 336 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_total_count_sp_proph_components = total_count_sp_model_proph.plot_components(total_count_sp_forecast_proph)
fig_total_count_sp_proph.show()

plt.savefig("total_count_sp_proph_components.png")

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#just realized i can dowload all the csv from my spell man model to add up all the forecasts. duhhh

#if not comebined in on DF make sure to upload random forst forecast from ecec data

#now combine forecast from both datasets
import pandas as pd


forecast_rf_prek1 = pd.read_csv("/content/forecast_rf_prek1 .csv")
forecast_rf_prek2 = pd.read_csv("/content/forecast_rf_prek2 .csv")
forecast_rf_pen_pre = pd.read_csv("/content/forecast_rf_pen_pre .csv")
forecast_rf_gramp_multi = pd.read_csv("/content/forecast_rf_gramp_multi .csv")
forecast_rf_pen_tod = pd.read_csv("/content/forecast_rf_pen_tod .csv")
forecast_rf_henr_tod = pd.read_csv("/content/forecast_rf_henr_tod .csv")
forecast_rf_gramp_tod = pd.read_csv("/content/forecast_rf_gramp_tod .csv")
forecast_rf_gramp_pre = pd.read_csv("/content/forecast_rf_gramp_pre .csv")
forecast_rf_henr_multi = pd.read_csv("/content/forecast_rf_henr_multi .csv")
forecast_rf_henr_inf = pd.read_csv("/content/forecast_rf_henr_inf .csv")
forecast_rf_pen_inf = pd.read_csv("/content/forecast_rf_pen_inf .csv")

#display a few to make sure they loaded in correctly
display(forecast_rf_prek1)
display(forecast_rf_prek2)
display(forecast_rf_pen_pre)
#combine all ECEC forecasts
all_room_forecasts_rf_ec = pd.concat([forecast_rf_prek1, forecast_rf_prek2, forecast_rf_pen_pre,
                                      forecast_rf_gramp_multi, forecast_rf_pen_tod,
                                      forecast_rf_henr_tod, forecast_rf_gramp_tod,
                                      forecast_rf_gramp_pre, forecast_rf_henr_multi,
                                      forecast_rf_henr_inf, forecast_rf_pen_inf], ignore_index=True)
display(all_room_forecasts_rf_ec)

display(all_room_forecasts_rf_ec)
display(all_room_forecasts_rf_sp)

#Combine all forecasts ECEC + Spellman

import pandas as pd

all_room_forecasts_rf_both = pd.concat([all_room_forecasts_rf_sp, all_room_forecasts_rf_ec], ignore_index=True)

display(all_room_forecasts_rf_both)

#save to csv
all_room_forecasts_rf_both.to_csv("all_room_forecasts_rf_both.csv", index=False)

display(total_forecasts_rf_both)

#BOTH DATA

#for some reason both totals are not adding up for the totalforecast,below. trying to fix

#make sure they are a date time object
total_forecasts_rf_both['Interval'] = pd.to_datetime(all_room_forecasts_rf_both['Interval'])

#make times are rounded
total_forecasts_rf_both['Interval'] = total_forecasts_rf_both['Interval'].dt.floor('30min')


#now group them all by the intercal term and calculate the total student count and staffing needs
#also reset index so interval is column
total_forecasts_rf_both = total_forecasts_rf_both.groupby('Interval').agg({'Predicted Student Count': 'sum', 'Predicted Staffing Needs': 'sum'}).reset_index()







#______testing code








#_____-testing code




#display results
display(total_forecasts_rf_both)
display(total_forecasts_rf_sp)

#save to csv
total_forecasts_rf_both.to_csv("total_forecasts_rf_both.csv", index=False)

#now get the Total sum for each day of the predicted week
#create a day column and remove it as datetime from interval
#this is giving the the total students in every 30 minute interval
# i dont think this necessarily a helpful stat
#need to convert interval to a datetime before using here
#total_forecasts_rf_both['Interval'] = pd.to_datetime(total_forecasts_rf_both['Interval'])

#create day columnn
#daytotal_forecasts_rf_both['Day'] = total_forecasts_rf_both['Interval'].dt.day_name()

#add totals up and group by day
#day_total_forecasts_rf_both = total_forecasts_rf_both.groupby('Day').agg({'Predicted Student Count': 'sum', 'Predicted Staffing Needs': 'sum'}).reset_index()
#display(day_total_forecasts_rf_both)

#calcualte average student count and staffing
 #(this would be an 7 day average, including the weekend on 3/1 and 3/2 )
 #this average also includes non working hours (where the student count and staff are 0)
 #would be helpful if we had data on the exact hours of the facilty so we can tweek the average to fit in those hours
 #instead we can just get remove any 0 entries

 #average for 7 day week, including non work hours (where staff and student 0)
 #so this is the average student count every 30 minutes
#need to remove
average_forecasts_rf_both_7 = total_forecasts_rf_both.agg({'Predicted Student Count': 'mean', 'Predicted Staffing Needs': 'mean'})

display(average_forecasts_rf_both_7)

#save to csv
average_forecasts_rf_both_7.to_csv("average_forecasts_rf_both.csv_7", index=False)

#combine 30 minute intercval counts from both datasets

#read in ecec csv
ec_count_full = pd.read_csv("/content/ecec_count_full.csv")

#read in spellman csv
sp_count_full = pd.read_csv("sp_count_full.csv")

#display both counts to check
display(ec_count_full)
display(sp_count_full)

#combine both datasets
both_count_full = pd.concat([ec_count_full, sp_count_full], ignore_index=True)

#display comboset
display(both_count_full)

#save to csv
both_count_full.to_csv("both_count_full.csv", index=False)

#continue for both data

#grab unforecasted data that has all student counts and staffing needs
total_both_count_full = pd.read_csv("both_count_full.csv")

display(total_both_count_full)

#convert interval to dt object
total_both_count_full['Interval'] = pd.to_datetime(total_both_count_full['Interval'])

#get total over all dates/intervals
total_both_count_full = total_both_count_full.groupby('Interval').agg({'Count': 'sum', 'Staffing Needs': 'sum'}).reset_index()

display(total_both_count_full)

#save as csv (this what we use for prophet)
total_both_count_full.to_csv("total_both_count_full.csv", index=False)

#get total by week day
#now add together total counts across all classrooms for each day
day_total_both_count_full = pd.read_csv("both_count_full.csv")
day_total_both_count_full['Day'] = total_both_count_full['Interval'].dt.day_name()
day_total_both_count_full = day_total_both_count_full.groupby('Day').agg({'Count': 'sum', 'Staffing Needs': 'sum'}).reset_index()

day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']

#for some reason it showing days out of order?? Need to fix this
# sort the daus in order for the data the day order
day_total_both_count_full['Day'] = pd.Categorical(day_total_both_count_full['Day'], categories=day_order, ordered=True)
day_total_both_count_full = day_total_both_count_full.sort_values('Day')

display(day_total_both_count_full)


#day_total_both_count_full.to_csv("day_total_both_count_full.csv", index=False)





#day_total_both_count_full.to_csv("day_total_both_count_full.csv", index=False)

#this didnt fix problem, idk whats up

#Prophet forecast for BOTH ECEC AND SP ADDED TOGETHER
import pandas as pd
import numpy as np
from prophet import Prophet
import matplotlib.pyplot as plt


# Read in data, (filter out  data from combined dataset)
total_count_both_data_proph= pd.read_csv("total_both_count_full.csv")

#keep only the dates and y vlaues
total_count_both_data_proph = total_count_both_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
total_count_both_data_proph = pd.DataFrame(total_count_both_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

total_count_both_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

total_count_both_model_proph.fit(total_count_both_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_total_count_both = total_count_both_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
total_count_both_forecast_proph = total_count_both_model_proph.predict(future_total_count_both)

total_count_both_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecastProph_week_total_count_both = total_count_both_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecastProph_week_total_count_both)

#looking at this dataframe while prophet is able to capture teh staffing trends, as far as actaul counts it is very off, even has negatives!
final_forecastProph_week_total_count_both.to_csv("final_forecastProph_week_total_count_both.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_total_count_both_proph =  total_count_both_model_proph.plot(total_count_both_forecast_proph)
fig_total_count_both_proph.show()
plt.savefig("total_count_both_proph.png")

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 336 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_total_count_both_proph_components = total_count_both_model_proph.plot_components(total_count_both_forecast_proph)
fig_total_count_both_proph.show()

plt.savefig("total_count_both_proph_components.png")

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend