# -*- coding: utf-8 -*-
"""EcecModel(Complete).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AFJ_ztHTuCCQs7iKTeLjOPAF8TcORMyE
"""

#!pip install --upgrade numpy
#!pip install --upgrade pandas

#!pip uninstall numpy -y
#!pip install numpy

"""ORIGINAL CODE START
HERE
"""

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "/content/ECEC 2022 Student Sign In and Out.xlsx" #had to change the path to run in colab, before compiling remember to change back to toriginal code
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
ecec_22_df = raw_df.iloc[6:].copy()
ecec_22_df.columns = new_columns

# Step 5: Drop completely empty columns
ecec_22_df = ecec_22_df.loc[:, ecec_22_df.columns.notnull()]
ecec_22_df = ecec_22_df.dropna(axis=1, how='all')

# Optional: Reset index
ecec_22_df.reset_index(drop=True, inplace=True)
ecec_22_df['Year'] = 2022
# Preview result
display(ecec_22_df.head())
ecec_22_df.to_csv("full_dataset_22.csv", index=False) #had to change the path to run in colab, before compiling remember to change back to toriginal code

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "/content/ECEC 2023 Student Sign In and Out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
ecec_23_df = raw_df.iloc[6:].copy()
ecec_23_df.columns = new_columns

# Step 5: Drop completely empty columns
ecec_23_df = ecec_23_df.loc[:, ecec_23_df.columns.notnull()]
ecec_23_df = ecec_23_df.dropna(axis=1, how='all')

# Optional: Reset index
ecec_23_df.reset_index(drop=True, inplace=True)
ecec_23_df['Year'] = 2023

# Preview result
display(ecec_23_df.head())

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "/content/ECEC 2024 Student Sign In and Out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
ecec_24_df = raw_df.iloc[6:].copy()
ecec_24_df.columns = new_columns

# Step 5: Drop completely empty columns
ecec_24_df = ecec_24_df.loc[:, ecec_24_df.columns.notnull()]
ecec_24_df = ecec_24_df.dropna(axis=1, how='all')

# Optional: Reset index
ecec_24_df.reset_index(drop=True, inplace=True)
ecec_24_df['Year'] = 2024

# Preview result
display(ecec_24_df.head())

import pandas as pd
from IPython.display import display

# Load Excel while skipping the metadata rows
file_path = "/content/ECEC 2025 01012025-02282025 Student Sign In and Out.xlsx"
excel = pd.ExcelFile(file_path)

# Step 1: Read full data including headers
raw_df = excel.parse("Sign In Out Times Report")

# Step 2: Extract header rows
# Step 2 (updated): Forward fill dates so OUT columns get correct date labels
header_row_1 = raw_df.iloc[4].ffill()  # Fill NaN with previous date (for OUT columns)
header_row_2 = raw_df.iloc[5]          # IN/OUT labels


# Step 3: Combine to create multi-level or unified column headers
new_columns = []
for col1, col2 in zip(header_row_1, header_row_2):
    if pd.notna(col1) and pd.notna(col2):
        new_columns.append(f"{col1.strip()}_{col2.strip().upper()}")
    elif pd.notna(col1):
        new_columns.append(col1.strip())
    else:
        new_columns.append("")

# Step 4: Read the actual data starting from row 6
ecec_25_df = raw_df.iloc[6:].copy()
ecec_25_df.columns = new_columns

# Step 5: Drop completely empty columns
ecec_25_df = ecec_25_df.loc[:, ecec_25_df.columns.notnull()]
ecec_25_df = ecec_25_df.dropna(axis=1, how='all')

# Optional: Reset index
ecec_25_df.reset_index(drop=True, inplace=True)
ecec_25_df['Year'] = 2025

# Preview result
display(ecec_25_df.head())
ecec_25_df.to_csv("full_dataset.csv", index=False)

print("Duplicate columns in ecec_22_df:", ecec_22_df.columns[ecec_22_df.columns.duplicated()])
print("Duplicate columns in ecec_23_df:", ecec_23_df.columns[ecec_23_df.columns.duplicated()])
print("Duplicate columns in ecec_24_df:", ecec_24_df.columns[ecec_24_df.columns.duplicated()])
print("Duplicate columns in ecec_25_df:", ecec_25_df.columns[ecec_25_df.columns.duplicated()])

"""Version 1 of concatated data where I will 1) try preserve the times, remove text from times and then also condense it so that matches the data format of ecec_long_in_format. doing this so I can then merge the datas so that corrct in and out times will align with the correct student and the correct date"""

#version 1 (this gonna be messsy)
import pandas as pd
import numpy as np

# Concatenate all cleaned DataFrames into one
ecec_time = pd.concat([ecec_22_df, ecec_23_df, ecec_24_df, ecec_25_df], axis=0, ignore_index=True)

# Reorder columns by month
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

# Separate the first 5 columns
first_columns = ecec_time.columns[:4].tolist()

# Identify month-related columns (after the first 5 columns)
month_columns = [col for col in ecec_time.columns[4:] if any(col.startswith(month) for month in month_order)]
other_columns = [col for col in ecec_time.columns[4:] if col not in month_columns]

# Sort month columns by month order
sorted_month_columns = sorted(month_columns, key=lambda col: (month_order.index(col[:3]), col))

# Combine the first 5 columns, sorted month columns, and other columns
ecec_time = ecec_time[first_columns + sorted_month_columns + other_columns]

#Replace all Nan with 0s
ecec_time = ecec_time.fillna(0)

# Display the cleaned and transformed DataFrame
print("Cleaned and Transformed Combined DataFrame Preview:")
display(ecec_time)

# Export the transformed DataFrame to a CSV file
ecec_time.to_csv("combined_ecec_time.csv", index=False)

# drop _OUT columns (created a seperate datafram without the out columns) this for Time ecec dataframe
ecec_in_time = ecec_time.loc[:, ~ecec_time.columns.str.endswith('_OUT')]
# reset index
ecec_in_time.reset_index(drop=True, inplace=True)
#save to csv
ecec_in_time.to_csv("combined_ecec_binomial_no_out_time.csv", index=False)

# drop _IN columns (created a seperate datafram without the in columns)
ecec_out_time = ecec_time.loc[:, ~ecec_time.columns.str.endswith('_IN')]
# reset index
ecec_out_time.reset_index(drop=True, inplace=True)
#save to csv
ecec_out_time.to_csv("combined_ecec_binomial_no_in_time.csv", index=False)

#now will further condense/ clean data with only IN columns (for columns with times)
import pandas as pd

metadata_columns = ['Record ID', 'Student Status', 'Room', 'Tags', 'Year']  # Include 'Year' in metadata

# Identify date columns (columns with month names)
date_columns = [col for col in ecec_in_time.columns if any(month in col for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                                                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])]

# Melt the DataFrame to create a long format
ecec_long_in_time = ecec_in_time.melt(id_vars=metadata_columns,
                            value_vars=date_columns,
                            var_name='Date_Event',
                            value_name='Time_IN')


# Split 'Date_Event' into 'Month Day' and 'Event' (e.g., Jan 02 and IN)
ecec_long_in_time[['Month_Day', 'Event_IN']] = ecec_long_in_time['Date_Event'].str.rsplit('_', n=1, expand=True)

# Clean 'Month_Day' string and construct the full date
ecec_long_in_time['Month_Day'] = ecec_long_in_time['Month_Day'].str.strip()
date_strings = ecec_long_in_time['Month_Day'] + " " + ecec_long_in_time['Year'].astype(str)
ecec_long_in_time['Date'] = pd.to_datetime(date_strings, format='%b %d %Y', errors='coerce')

# Drop rows with invalid dates or zero values
ecec_long_in_time = ecec_long_in_time[(~ecec_long_in_time['Date'].isna()) & (ecec_long_in_time['Time_IN'] != 0)]

# Drop temporary columns
ecec_long_in_time.drop(columns=['Date_Event', 'Month_Day', 'Year'], inplace=True)





ecec_long_in_time.reset_index(drop=True, inplace=True)

# Preview the reshaped DataFrame
display(ecec_long_in_time.head())

# Save the reshaped DataFrame to a CSV file
ecec_long_in_time.to_csv("ecec_long_in_time_format.csv", index=False)

#now will further condense/ clean data with only OUT columns (for columns with times)
import pandas as pd

metadata_columns = ['Record ID', 'Student Status', 'Room', 'Tags', 'Year']  # Include 'Year' in metadata

# Identify date columns (columns with month names)
date_columns = [col for col in ecec_out_time.columns if any(month in col for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                                                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])]

# Melt the DataFrame to create a long format
ecec_long_out_time = ecec_out_time.melt(id_vars=metadata_columns,
                            value_vars=date_columns,
                            var_name='Date_Event',
                            value_name='Time_OUT')


# Split 'Date_Event' into 'Month Day' and 'Event' (e.g., Jan 02 and IN)
ecec_long_out_time[['Month_Day', 'Event_OUT']] =ecec_long_out_time['Date_Event'].str.rsplit('_', n=1, expand=True)

# Clean 'Month_Day' string and construct the full date
ecec_long_out_time['Month_Day'] = ecec_long_out_time['Month_Day'].str.strip()
date_strings = ecec_long_out_time['Month_Day'] + " " + ecec_long_out_time['Year'].astype(str)
ecec_long_out_time['Date'] = pd.to_datetime(date_strings, format='%b %d %Y', errors='coerce')

# Drop rows with invalid dates or zero values
ecec_long_out_time = ecec_long_out_time[(~ecec_long_out_time['Date'].isna()) & (ecec_long_out_time['Time_OUT'] != 0)]

# Drop temporary columns
ecec_long_out_time.drop(columns=['Date_Event', 'Month_Day', 'Year'], inplace=True)






# Reset the index
ecec_long_out_time.reset_index(drop=True, inplace=True)

# Preview the reshaped DataFrame
display(ecec_long_out_time.head())

# Save the reshaped DataFrame to a CSV file
ecec_long_out_time.to_csv("ecec_long_out_time_format.csv", index=False)

#now going to add the removed column Time_OUT to the ecec_long_in_time dataframe
ecec_long_in_time['Time_OUT'] = remove_time_out

#display newly added colum in the dataframe
display(ecec_long_in_time.head())

#going to reset the values of the dataframe for ecec long time in for better readabilty

# State the colum order wanted
desired_column_order = ['Record ID', 'Student Status', 'Room', 'Tags', 'Time_IN', 'Time_OUT', 'Date']

# Reorder columns by setting equal to orignal data frame
ecec_long_in_time = ecec_long_in_time[desired_column_order]

# Display the DataFrame with reordered columns
display(ecec_long_in_time.head())

#save new format to csv file
ecec_long_in_time.to_csv("ecec_long_in_time_format.csv", index=False)

#now going to extract the times from the Time_In and Time_Out

import pandas as pd
import re
from dateutil.parser import parse

def extract_time(text):
    match = re.search(r'(\d{1,2}:\d{2} (?:AM|PM))', str(text))
    if match:
        return match.group(1)
    else:
        return None

#apply function to date frame columns to extract time
ecec_long_in_time['Time_IN'] = ecec_long_in_time['Time_IN'].apply(extract_time)
ecec_long_in_time['Time_OUT'] = ecec_long_in_time['Time_OUT'].apply(extract_time)

#display times only in data frame
display(ecec_long_in_time.head())

from datetime import datetime, timedelta
#check data type for all columns, just to see what is already a datetime
print(ecec_long_in_time.dtypes)

#now going to combine the date and time columns together and then convert them into date time objects

display(ecec_long_in_time.head())

# Extract time component from 'Time_IN' and 'Time_OUT' and convert to datetime.time
# Handle NaT values by replacing them with a default time (e.g., 00:00:00)
default_time = datetime.min.time()  # or any other desired default time
ecec_long_in_time['Time_IN'] = pd.to_datetime(ecec_long_in_time['Time_IN']).dt.time.fillna(default_time)

ecec_long_in_time['Time_OUT'] = pd.to_datetime(ecec_long_in_time['Time_OUT']).dt.time.fillna(default_time)

# Convert 'Date' column to datetime.date if it's a Timestamp
ecec_long_in_time['Date'] = pd.to_datetime(ecec_long_in_time['Date']).dt.date

print(ecec_long_in_time.dtypes)

#now going to combine the date and time columns together and then convert them into date time objects

from datetime import datetime
#check data type for all columns
print(ecec_long_in_time.dtypes)





# datetime.combine
ecec_long_in_time['Time_IN'] = ecec_long_in_time.apply(lambda row: datetime.combine(row['Date'], row['Time_IN']), axis=1)
ecec_long_in_time['Time_OUT'] = ecec_long_in_time.apply(lambda row: datetime.combine(row['Date'], row['Time_OUT']), axis=1)

display(ecec_long_in_time.head())




ecec_long_in_time.to_csv("ecec_long_in_time_format.csv", index=False)


#DO NOT DELETE THE DATE COLUMN!!! LEAVE IT

#now sort the dataframe by date (earliest)
ecec_long_in_time = ecec_long_in_time.sort_values(by=['Time_IN'])

display(ecec_long_in_time.head())


ecec_long_in_time.to_csv("ecec_long_in_time_format.csv", index=False)

#Find all of the unique room names included on data frame
unique_rooms = ecec_long_in_time['Room'].unique()
print(unique_rooms)

"""START WITH ECEC DATA"""

#Starting with ECEC data going to create new dataframes for Infants, Multi-Age, Toddlers, Preschool, Pre-K

#Start with Room for Pre-K1

#create new dataframe to filter out only prek-k1 entries
pre_k1_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Pre-K1']

#display new dataframe
display(pre_k1_ecec.head())

#save new data frame to a csv
pre_k1_ecec.to_csv("pre_k1_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K1
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=pre_k1_ecec['Time_IN'].min().floor('30min'),
                          end=pre_k1_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = pre_k1_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (pre_k1_ecec['Time_IN'] <= end) & (pre_k1_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Pre-K1', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
pre_k1_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(pre_k1_ecec_30min_counts)

#save to csv
pre_k1_ecec_30min_counts.to_csv("pre_k1_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#for pre-k1 in ecec data the ratio is 12 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 12:
        return 1  # 1 staff member for up to 12 students
    elif student_count <= 24:
        return 2  # 2 staff members for 13-24 students
    elif student_count <= 36:
        return 3  # 3 staff members for 25-36 students
    elif student_count <= 48:
        return 4  # 4 staff members for 37-48 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
pre_k1_ecec_30min_counts['Staffing Needs'] = pre_k1_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(pre_k1_ecec_30min_counts)

#save to csv
pre_k1_ecec_30min_counts.to_csv("pre_k1_ecec_30min_counts.csv", index=False)

#PRE-K2 data frame
#create new dataframe to filter out only prek-k1 entries
pre_k2_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Pre-K2']

#display new dataframe
display(pre_k2_ecec.head())

#save new data frame to a csv
pre_k2_ecec.to_csv("pre_k2_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=pre_k2_ecec['Time_IN'].min().floor('30min'),
                          end=pre_k2_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = pre_k2_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (pre_k2_ecec['Time_IN'] <= end) & (pre_k2_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Pre-K2', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
pre_k2_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(pre_k2_ecec_30min_counts)

#save to csv
pre_k2_ecec_30min_counts.to_csv("pre_k2_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#for pre-k in ecec data the ratio is 12 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 12:
        return 1  # 1 staff member for up to 12 students
    elif student_count <= 24:
        return 2  # 2 staff members for 13-24 students
    elif student_count <= 36:
        return 3  # 3 staff members for 25-36 students
    elif student_count <= 48:
        return 4  # 4 staff members for 37-48 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
pre_k2_ecec_30min_counts['Staffing Needs'] = pre_k2_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(pre_k2_ecec_30min_counts)

#save to csv
pre_k2_ecec_30min_counts.to_csv("pre_k2_ecec_30min_counts.csv", index=False)

#create data frame for Pennie Preschool 1

#create new dataframe to filter out entries
pen_pre_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Pennie Preschool 1']

#display new dataframe
display(pen_pre_ecec.head())

#save new data frame to a csv
pen_pre_ecec.to_csv("pen_pre_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=pen_pre_ecec['Time_IN'].min().floor('30min'),
                          end=pen_pre_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = pen_pre_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (pen_pre_ecec['Time_IN'] <= end) & (pen_pre_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Pennie Preschool 1', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
pen_pre_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(pen_pre_ecec_30min_counts)

#save to csv
pen_pre_ecec_30min_counts.to_csv("pen_pre_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#preschool ratio is 10 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 10:
        return 1  # 1 staff member for up to 10 students
    elif student_count <= 20:
        return 2  # 2 staff members for 11-20 students
    elif student_count <= 30:
        return 3  # 3 staff members for 21-30 students
    elif student_count <= 40:
        return 4  # 4 staff members for 31-40 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
pen_pre_ecec_30min_counts['Staffing Needs'] = pen_pre_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(pen_pre_ecec_30min_counts)

#save to csv
pen_pre_ecec_30min_counts.to_csv("pen_pre_ecec_30min_counts.csv", index=False)

#create data frame for Grampy Tom Multi-Age

#create new dataframe to filter out entries
gramp_multi_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Grampy Tom Multi-Age']

#display new dataframe
display(gramp_multi_ecec.head())

#save new data frame to a csv
gramp_multi_ecec.to_csv("gramp_multi_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=gramp_multi_ecec['Time_IN'].min().floor('30min'),
                          end=gramp_multi_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = gramp_multi_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (gramp_multi_ecec['Time_IN'] <= end) & (gramp_multi_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Grampy Tom Multi-Age', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way
gramp_multi_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(gramp_multi_ecec_30min_counts)

#save to csv
gramp_multi_ecec_30min_counts.to_csv("gramp_multi_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#multi age ratio is 4 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 4:
        return 1  # 1 staff member for up to 4 students
    elif student_count <= 8:
        return 2  # 2 staff members for 5-8 students
    elif student_count <= 12:
        return 3  # 3 staff members for 9-12 students
    elif student_count <= 16:
        return 4  # 4 staff members for 13-16 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
gramp_multi_ecec_30min_counts['Staffing Needs'] = gramp_multi_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(gramp_multi_ecec_30min_counts)

#save to csv
gramp_multi_ecec_30min_counts.to_csv("gramp_multi_ecec_30min_counts.csv", index=False)

#create data frame for Pennie Toddlers

#create new dataframe to filter out entries
pen_tod_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Pennie Toddlers']

#display new dataframe
display(pen_tod_ecec.head())

#save new data frame to a csv
pen_tod_ecec.to_csv("pen_tod_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=pen_tod_ecec['Time_IN'].min().floor('30min'),
                          end=pen_tod_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = pen_tod_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (pen_tod_ecec['Time_IN'] <= end) & (pen_tod_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Pennie Toddlers', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

pen_tod_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(pen_tod_ecec_30min_counts)

#save to csv
pen_tod_ecec_30min_counts.to_csv("pen_tod_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Toddler ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
pen_tod_ecec_30min_counts['Staffing Needs'] = pen_tod_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(pen_tod_ecec_30min_counts)

#save to csv
pen_tod_ecec_30min_counts.to_csv("pen_tod_ecec_30min_counts.csv", index=False)

#create data frame for Henry Toddlers

#create new dataframe to filter out entries
henr_tod_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Henry Toddlers']

#display new dataframe
display(henr_tod_ecec.head())

#save new data frame to a csv
henr_tod_ecec.to_csv("henr_tod_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=henr_tod_ecec['Time_IN'].min().floor('30min'),
                          end=henr_tod_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = henr_tod_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (henr_tod_ecec['Time_IN'] <= end) & (henr_tod_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Henry Toddlers', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

henr_tod_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(henr_tod_ecec_30min_counts)

#save to csv
henr_tod_ecec_30min_counts.to_csv("henr_tod_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#toddler have 6:1 ratio

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
henr_tod_ecec_30min_counts['Staffing Needs'] = henr_tod_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(henr_tod_ecec_30min_counts)

#save to csv
henr_tod_ecec_30min_counts.to_csv("henr_tod_ecec_30min_counts.csv", index=False)

#create data frame for Grampy Tom Toddlers

#create new dataframe to filter out entries
gramp_tod_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Grampy Tom Toddlers']

#display new dataframe
display(gramp_tod_ecec.head())

#save new data frame to a csv
gramp_tod_ecec.to_csv("gramp_tod_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=gramp_tod_ecec['Time_IN'].min().floor('30min'),
                          end=gramp_tod_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = gramp_tod_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (gramp_tod_ecec['Time_IN'] <= end) & (gramp_tod_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Grampy Tom Toddlers', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

gramp_tod_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(gramp_tod_ecec_30min_counts)

#save to csv
gramp_tod_ecec_30min_counts.to_csv("gramp_tod_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#toddler have 6:1 ratio

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
gramp_tod_ecec_30min_counts['Staffing Needs'] = gramp_tod_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(gramp_tod_ecec_30min_counts)

#save to csv
gramp_tod_ecec_30min_counts.to_csv("gramp_tod_ecec_30min_counts.csv", index=False)

#create data frame for Grampy Tom Preschool

#create new dataframe to filter out entries
gramp_pre_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Grampy Tom Preschool']

#display new dataframe
display(gramp_pre_ecec.head())

#save new data frame to a csv
gramp_pre_ecec.to_csv("gramp_pre_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


# Create the 30 min time interval based on time and time out columns
time_range = pd.date_range(start=gramp_pre_ecec['Time_IN'].min().floor('30min'),
                          end=gramp_pre_ecec['Time_OUT'].max().ceil('30min'),
                          freq='30min') #make sure the frequecy is spaced by 30 mins
intervals = [(start, start + pd.Timedelta(minutes=30)) for start in time_range[:-1]]

#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = gramp_pre_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (gramp_pre_ecec['Time_IN'] <= end) & (gramp_pre_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Grampy Tom Preschool', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))

#make a new data frame, with new variable interval that will hold the 30 mins at each start time
#gramp_pre_ecec_30min_counts = pd.DataFrame({'Interval': time_range[:-1], 'Count': counts})
#now I can call on the data frame in a cool way

gramp_pre_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(gramp_pre_ecec_30min_counts)

#save to csv
gramp_pre_ecec_30min_counts.to_csv("gramp_pre_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#preschool ratio is 10 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 10:
        return 1  # 1 staff member for up to 10 students
    elif student_count <= 20:
        return 2  # 2 staff members for 11-20 students
    elif student_count <= 30:
        return 3  # 3 staff members for 21-30 students
    elif student_count <= 40:
        return 4  # 4 staff members for 31-40 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
gramp_pre_ecec_30min_counts['Staffing Needs'] = gramp_pre_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(gramp_pre_ecec_30min_counts)

#save to csv
gramp_pre_ecec_30min_counts.to_csv("gramp_pre_ecec_30min_counts.csv", index=False)

#create data frame for Henry Multi-Age

#create new dataframe to filter out entries
henr_multi_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Henry Multi-Age']

#display new dataframe
display(henr_multi_ecec.head())

#save new data frame to a csv
henr_multi_ecec.to_csv("henr_multi_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = henr_multi_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (henr_multi_ecec['Time_IN'] <= end) & (henr_multi_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Henry Multi-Age', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))

#make a new data frame, with new variable interval that will hold the 30 mins at each start time
#gramp_pre_ecec_30min_counts = pd.DataFrame({'Interval': time_range[:-1], 'Count': counts})
#now I can call on the data frame in a cool way

henr_multi_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(henr_multi_ecec_30min_counts)

#save to csv
henr_multi_ecec_30min_counts.to_csv("henr_multi_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Multi Age ratio is 4 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 4:
        return 1  # 1 staff member for up to 4 students
    elif student_count <= 8:
        return 2  # 2 staff members for 5-8 students
    elif student_count <= 12:
        return 3  # 3 staff members for 9-12 students
    elif student_count <= 16:
        return 4  # 4 staff members for 13-16 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
henr_multi_ecec_30min_counts['Staffing Needs'] = henr_multi_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(henr_multi_ecec_30min_counts)

#save to csv
henr_multi_ecec_30min_counts.to_csv("henr_multi_ecec_30min_counts.csv", index=False)

#create data frame for Henry Infants

#create new dataframe to filter out entries
henr_inf_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Henry Infants']

#display new dataframe
display(henr_inf_ecec.head())

#save new data frame to a csv
henr_inf_ecec.to_csv("henr_inf_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = henr_inf_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (henr_inf_ecec['Time_IN'] <= end) & (henr_inf_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Henry Infants', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

henr_inf_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(henr_inf_ecec_30min_counts)

#save to csv
henr_inf_ecec_30min_counts.to_csv("henr_inf_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Infant ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
henr_inf_ecec_30min_counts['Staffing Needs'] = henr_inf_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(henr_inf_ecec_30min_counts)

#save to csv
henr_inf_ecec_30min_counts.to_csv("henr_inf_ecec_30min_counts.csv", index=False)

#create data frame for Pennie Infants

#create new dataframe to filter out entries
pen_inf_ecec = ecec_long_in_time[ecec_long_in_time['Room'] == 'Pennie Infants']

#display new dataframe
display(pen_inf_ecec.head())

#save new data frame to a csv
pen_inf_ecec.to_csv("pen_inf_ecec.csv", index=False)

#determine daily student count in 30 minute intervals for Pre-K2
import pandas as pd


#create a function to count the number of students presence within the interval
def count_present(interval):
    start, end = interval
    count = pen_inf_ecec[ #trying to modify code so that it will keep the Room column in final dataframe
      (pen_inf_ecec['Time_IN'] <= end) & (pen_inf_ecec['Time_OUT'] >= start)
    ].shape[0]  # Get the number of rows (students)

       #retyrn room and count
    return {'Interval': start, 'Room': 'Pennie Infants', 'Count': count}

#have the counts done parellel to one another otherwise it will take forever to process
import multiprocessing as mp

with mp.Pool(processes=mp.cpu_count()) as pool:
   counts = pool.map(count_present, intervals)
#counts = list(map(count_present, intervals))


#now I can call on the data frame in a cool way

pen_inf_ecec_30min_counts = pd.DataFrame(counts)

#show the results of the new data frame
display(pen_inf_ecec_30min_counts)

#save to csv
pen_inf_ecec_30min_counts.to_csv("pen_inf_ecec_30min_counts.csv", index=False)

#now based on these counts need to also give a count that will display the staffing needs

#Infant ratio is 6 students : 1 staff

# Function to determine staffing needs
def calculate_staffing_needs(student_count):
    """Calculates staffing needs based on the student count."""
    if student_count == 0:
        return 0  # 0 staff members for 0 students
    elif student_count < 0:
        return "Error: Negative Count!"
    elif student_count <= 6:
        return 1  # 1 staff member for up to 6 students
    elif student_count <= 12:
        return 2  # 2 staff members for 7-12 students
    elif student_count <= 18:
        return 3  # 3 staff members for 13-18 students
    elif student_count <= 24:
        return 4  # 4 staff members for 19-24 students
    else:
        return "Error: count ratio not accounted for"

# Apply the function to create the 'Staffing Needs' column
pen_inf_ecec_30min_counts['Staffing Needs'] = pen_inf_ecec_30min_counts['Count'].apply(calculate_staffing_needs)

# Display the updated DataFrame
display(pen_inf_ecec_30min_counts)

#save to csv
pen_inf_ecec_30min_counts.to_csv("pen_inf_ecec_30min_counts.csv", index=False)

#now going to combine all 30 minute dataframes with the counts, into 1 data frame

ecec_count_full = pd.concat([gramp_pre_ecec_30min_counts, gramp_multi_ecec_30min_counts, gramp_tod_ecec_30min_counts, henr_inf_ecec_30min_counts, henr_multi_ecec_30min_counts, henr_tod_ecec_30min_counts, pen_inf_ecec_30min_counts, pen_pre_ecec_30min_counts, pen_tod_ecec_30min_counts, pre_k1_ecec_30min_counts, pre_k2_ecec_30min_counts  ])

display(ecec_count_full)

#save to csv
ecec_count_full.to_csv("ecec_count_full.csv", index=False)

"""ATTEMPT 1.1 Going to try and build a multivariate regression using random forests"""

#Random forest model for Prek1

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
#import plotly.express as px #use for heat map

prek1_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Pre-K1']

prek1_data_rf['hour'] = prek1_data_rf['Interval'].dt.hour
prek1_data_rf['year'] = prek1_data_rf['Interval'].dt.year
prek1_data_rf['month'] = prek1_data_rf['Interval'].dt.month
prek1_data_rf['day'] = prek1_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = prek1_data_rf[features]
Y = prek1_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?




# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 ) #only difference between this and a decision tree is that we declare it as
    #a random forest modifier, nestimators is the number of trees in the forest, njobs is how many processer core your willing to allocate to
    # processing yourr random forest n_job = -1 means use all of the available processor cores (if you ahve 12 cores then it will run 12 trees at a time
    # simulatneously)<-means we can run 12x faster then if we set njobs = 1 and it only use 1 processors
    #using random state makes sure that each time we run this we get the same tree, instad of giving us different trees each time

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)
# Print the accuracy score of the fitted model
#print("The random forest has an accuracy of : %s\n"  #cant use this here because it only works when not using multivariate regression
	#% str(accuracy_score(fpred, yt)))


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])

# Calculate R-squared for staffing needs
#pred staffing needs
#r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])

# Print the results
#print("MSE for Student Count:", mse_student_count)
#print("R-squared for Staffing Needs:", r2_staffing_needs)

#since cant do print accuracy within moodel will do so outside of model
# Evaluate the model separately for each target variable
#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
# Define start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')
# Generate future_intervals with the same length as future_predictions_rf_prek1
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

#future_dates_rf_prek1 = pd.date_range(start='2025-03-01', end='2025-03-07', freq='30min') #this will do one week ahead of the end of the data we have
future_data_rf_prek1 = pd.DataFrame({'Interval': future_intervals})

#future_data_rf_prek1 = pd.DataFrame({'Interval': future_dates_rf_prek1})

future_data_rf_prek1['hour'] = future_data_rf_prek1['Interval'].dt.hour
future_data_rf_prek1['year'] = future_data_rf_prek1['Interval'].dt.year
future_data_rf_prek1['month'] = future_data_rf_prek1['Interval'].dt.month
future_data_rf_prek1['day'] = future_data_rf_prek1['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_prek1 = fclf.predict(future_data_rf_prek1[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:
#future_data_rf_prek1['Predicted_Staffing'] = future_predictions_prek1
#forecast_week_prek1_gam = future_data[['Interval', 'Predicted_Staffing','Room']].round() #need to put this round here so that it isnt predicting small negative ot weird numbers. Idk controversial decison. I'l have to come back to this

forecast_rf_prek1 = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_prek1[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_prek1[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_prek1 )

forecast_rf_prek1 .to_csv("forecast_rf_prek1 .csv", index=False)

#Random forest for PreK2


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


prek2_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Pre-K2']

prek2_data_rf['hour'] = prek2_data_rf['Interval'].dt.hour
prek2_data_rf['year'] = prek2_data_rf['Interval'].dt.year
prek2_data_rf['month'] = prek2_data_rf['Interval'].dt.month
prek2_data_rf['day'] = prek2_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = prek2_data_rf[features]
Y = prek2_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)

# Print the accuracy score of the fitted model
#print("The random forest has an accuracy of : %s\n"  #cant use this here because it only works when not using multivariate regression
	#% str(accuracy_score(fpred, yt)))


# Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_prek2
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_prek2 = pd.DataFrame({'Interval': future_intervals})


future_data_rf_prek2['hour'] = future_data_rf_prek2['Interval'].dt.hour
future_data_rf_prek2['year'] = future_data_rf_prek2['Interval'].dt.year
future_data_rf_prek2['month'] = future_data_rf_prek2['Interval'].dt.month
future_data_rf_prek2['day'] = future_data_rf_prek2['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_prek2 = fclf.predict(future_data_rf_prek2[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_prek2 = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_prek2[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_prek2[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_prek2 )

forecast_rf_prek2 .to_csv("forecast_rf_prek2 .csv", index=False)

#Random forest for Pennie Preschool 1


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


pen_pre_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Pennie Preschool 1']

pen_pre_data_rf['hour'] = pen_pre_data_rf['Interval'].dt.hour
pen_pre_data_rf['year'] = pen_pre_data_rf['Interval'].dt.year
pen_pre_data_rf['month'] = pen_pre_data_rf['Interval'].dt.month
pen_pre_data_rf['day'] = pen_pre_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = pen_pre_data_rf[features]
Y = pen_pre_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_pen_pre
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_pen_pre = pd.DataFrame({'Interval': future_intervals})


future_data_rf_pen_pre['hour'] = future_data_rf_pen_pre['Interval'].dt.hour
future_data_rf_pen_pre['year'] = future_data_rf_pen_pre['Interval'].dt.year
future_data_rf_pen_pre['month'] = future_data_rf_pen_pre['Interval'].dt.month
future_data_rf_pen_pre['day'] = future_data_rf_pen_pre['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_pen_pre = fclf.predict(future_data_rf_pen_pre[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_pen_pre = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_pen_pre[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_pen_pre[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_pen_pre )

forecast_rf_pen_pre .to_csv("forecast_rf_pen_pre .csv", index=False)

#Random forest for Grampy Tom Multi-Age


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


gramp_multi_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Grampy Tom Multi-Age']

gramp_multi_data_rf['hour'] = gramp_multi_data_rf['Interval'].dt.hour
gramp_multi_data_rf['year'] = gramp_multi_data_rf['Interval'].dt.year
gramp_multi_data_rf['month'] = gramp_multi_data_rf['Interval'].dt.month
gramp_multi_data_rf['day'] = gramp_multi_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = gramp_multi_data_rf[features]
Y = gramp_multi_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_gramp_multi
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_gramp_multi = pd.DataFrame({'Interval': future_intervals})


future_data_rf_gramp_multi['hour'] = future_data_rf_gramp_multi['Interval'].dt.hour
future_data_rf_gramp_multi['year'] = future_data_rf_gramp_multi['Interval'].dt.year
future_data_rf_gramp_multi['month'] = future_data_rf_gramp_multi['Interval'].dt.month
future_data_rf_gramp_multi['day'] = future_data_rf_gramp_multi['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_gramp_multi = fclf.predict(future_data_rf_gramp_multi[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_gramp_multi = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_gramp_multi[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_gramp_multi[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_gramp_multi )

forecast_rf_gramp_multi .to_csv("forecast_rf_gramp_multi .csv", index=False)

#Random forest for Pennie Toddlers


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


pen_tod_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Pennie Toddlers']

pen_tod_data_rf['hour'] = pen_tod_data_rf['Interval'].dt.hour
pen_tod_data_rf['year'] = pen_tod_data_rf['Interval'].dt.year
pen_tod_data_rf['month'] = pen_tod_data_rf['Interval'].dt.month
pen_tod_data_rf['day'] = pen_tod_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = pen_tod_data_rf[features]
Y = pen_tod_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_pen_tod
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_pen_tod = pd.DataFrame({'Interval': future_intervals})


future_data_rf_pen_tod['hour'] = future_data_rf_pen_tod['Interval'].dt.hour
future_data_rf_pen_tod['year'] = future_data_rf_pen_tod['Interval'].dt.year
future_data_rf_pen_tod['month'] = future_data_rf_pen_tod['Interval'].dt.month
future_data_rf_pen_tod['day'] = future_data_rf_pen_tod['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_pen_tod = fclf.predict(future_data_rf_pen_tod[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_pen_tod = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_pen_tod[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_pen_tod[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_pen_tod )

forecast_rf_pen_tod .to_csv("forecast_rf_pen_tod .csv", index=False)

#Random forest for Henry Toddlers


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


henr_tod_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Henry Toddlers']

henr_tod_data_rf['hour'] = henr_tod_data_rf['Interval'].dt.hour
henr_tod_data_rf['year'] = henr_tod_data_rf['Interval'].dt.year
henr_tod_data_rf['month'] = henr_tod_data_rf['Interval'].dt.month
henr_tod_data_rf['day'] = henr_tod_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = henr_tod_data_rf[features]
Y = henr_tod_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_henr_tod
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_henr_tod = pd.DataFrame({'Interval': future_intervals})


future_data_rf_henr_tod['hour'] = future_data_rf_henr_tod['Interval'].dt.hour
future_data_rf_henr_tod['year'] = future_data_rf_henr_tod['Interval'].dt.year
future_data_rf_henr_tod['month'] = future_data_rf_henr_tod['Interval'].dt.month
future_data_rf_henr_tod['day'] = future_data_rf_henr_tod['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_henr_tod = fclf.predict(future_data_rf_henr_tod[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_henr_tod = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_henr_tod[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_henr_tod[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_henr_tod )

forecast_rf_henr_tod .to_csv("forecast_rf_henr_tod .csv", index=False)

#Random forest for Grampy Tom Toddlers


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


gramp_tod_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Grampy Tom Toddlers']

gramp_tod_data_rf['hour'] = gramp_tod_data_rf['Interval'].dt.hour
gramp_tod_data_rf['year'] = gramp_tod_data_rf['Interval'].dt.year
gramp_tod_data_rf['month'] = gramp_tod_data_rf['Interval'].dt.month
gramp_tod_data_rf['day'] = gramp_tod_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = gramp_tod_data_rf[features]
Y = gramp_tod_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_gramp_tod
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_gramp_tod = pd.DataFrame({'Interval': future_intervals})


future_data_rf_gramp_tod['hour'] = future_data_rf_gramp_tod['Interval'].dt.hour
future_data_rf_gramp_tod['year'] = future_data_rf_gramp_tod['Interval'].dt.year
future_data_rf_gramp_tod['month'] = future_data_rf_gramp_tod['Interval'].dt.month
future_data_rf_gramp_tod['day'] = future_data_rf_gramp_tod['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_gramp_tod = fclf.predict(future_data_rf_gramp_tod[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_gramp_tod = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_gramp_tod[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_gramp_tod[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_gramp_tod )

forecast_rf_gramp_tod .to_csv("forecast_rf_gramp_tod .csv", index=False)

#Random forest for Grampy Tom Preschool


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


gramp_pre_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Grampy Tom Preschool']

gramp_pre_data_rf['hour'] = gramp_pre_data_rf['Interval'].dt.hour
gramp_pre_data_rf['year'] = gramp_pre_data_rf['Interval'].dt.year
gramp_pre_data_rf['month'] = gramp_pre_data_rf['Interval'].dt.month
gramp_pre_data_rf['day'] = gramp_pre_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = gramp_pre_data_rf[features]
Y = gramp_pre_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_gramp_pre
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_gramp_pre = pd.DataFrame({'Interval': future_intervals})


future_data_rf_gramp_pre['hour'] = future_data_rf_gramp_pre['Interval'].dt.hour
future_data_rf_gramp_pre['year'] = future_data_rf_gramp_pre['Interval'].dt.year
future_data_rf_gramp_pre['month'] = future_data_rf_gramp_pre['Interval'].dt.month
future_data_rf_gramp_pre['day'] = future_data_rf_gramp_pre['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_gramp_pre = fclf.predict(future_data_rf_gramp_pre[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_gramp_pre = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_gramp_pre[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_gramp_pre[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_gramp_pre )

forecast_rf_gramp_pre .to_csv("forecast_rf_gramp_pre .csv", index=False)

#Random forest for Henry Infants


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


henr_inf_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Henry Infants']

henr_inf_data_rf['hour'] = henr_inf_data_rf['Interval'].dt.hour
henr_inf_data_rf['year'] = henr_inf_data_rf['Interval'].dt.year
henr_inf_data_rf['month'] = henr_inf_data_rf['Interval'].dt.month
henr_inf_data_rf['day'] = henr_inf_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = henr_inf_data_rf[features]
Y = henr_inf_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_henr_inf
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_henr_inf = pd.DataFrame({'Interval': future_intervals})


future_data_rf_henr_inf['hour'] = future_data_rf_henr_inf['Interval'].dt.hour
future_data_rf_henr_inf['year'] = future_data_rf_henr_inf['Interval'].dt.year
future_data_rf_henr_inf['month'] = future_data_rf_henr_inf['Interval'].dt.month
future_data_rf_henr_inf['day'] = future_data_rf_henr_inf['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_henr_inf = fclf.predict(future_data_rf_henr_inf[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_henr_inf = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_henr_inf[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_henr_inf[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_henr_inf )

forecast_rf_henr_inf .to_csv("forecast_rf_henr_inf .csv", index=False)

#Random forest for Henry Multi-Age


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


henr_multi_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Henry Multi-Age']

henr_multi_data_rf['hour'] = henr_multi_data_rf['Interval'].dt.hour
henr_multi_data_rf['year'] = henr_multi_data_rf['Interval'].dt.year
henr_multi_data_rf['month'] = henr_multi_data_rf['Interval'].dt.month
henr_multi_data_rf['day'] = henr_multi_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = henr_multi_data_rf[features]
Y = henr_multi_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_henr_multi
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_henr_multi = pd.DataFrame({'Interval': future_intervals})


future_data_rf_henr_multi['hour'] = future_data_rf_henr_multi['Interval'].dt.hour
future_data_rf_henr_multi['year'] = future_data_rf_henr_multi['Interval'].dt.year
future_data_rf_henr_multi['month'] = future_data_rf_henr_multi['Interval'].dt.month
future_data_rf_henr_multi['day'] = future_data_rf_henr_multi['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_henr_multi = fclf.predict(future_data_rf_henr_multi[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_henr_multi = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_henr_multi[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_henr_multi[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_henr_multi )

forecast_rf_henr_multi .to_csv("forecast_rf_henr_multi .csv", index=False)

#Random forest for Pennie Infants


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier


pen_inf_data_rf = ecec_count_full[ecec_count_full['Room'] == 'Pennie Infants']

pen_inf_data_rf['hour'] = pen_inf_data_rf['Interval'].dt.hour
pen_inf_data_rf['year'] = pen_inf_data_rf['Interval'].dt.year
pen_inf_data_rf['month'] = pen_inf_data_rf['Interval'].dt.month
pen_inf_data_rf['day'] = pen_inf_data_rf['Interval'].dt.weekday
#create features and targets #if doing large data set might be helpful to have room as one of the x features
features = ['hour', 'year', 'month','day']
targets = ['Count', 'Staffing Needs']

# Separate the labels from the inputs
X = pen_inf_data_rf[features]
Y = pen_inf_data_rf[targets]

# Randomly create train and test data
x, xt, y, yt = train_test_split(X, Y, test_size = 0.3, random_state=42) #keep 10% for testing and 90% for training, #random state allows us to change things without making everything random each time we run. it keeps it in a single state?



# Generate the random forest model
forest = RandomForestClassifier(n_estimators=2000,
	n_jobs = -1, random_state=42 )

# Fit the model to the training data
fclf = forest.fit(x, y) #fclf is the model
# Make predictions
fpred = fclf.predict(xt)




#Calculate MSE for student count
#pred student count
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])


#Student Count (Regression)
mse_student_count = mean_squared_error(yt['Count'], fpred[:, 0])
print("MSE for Student Count:", mse_student_count)

# Staffing Needs (Classification)
accuracy_staffing_needs = accuracy_score(yt['Staffing Needs'], fpred[:, 1])
print("Accuracy for Staffing Needs:", accuracy_staffing_needs)
# Calculate R-squared for staffing needs
r2_staffing_needs = r2_score(yt['Staffing Needs'], fpred[:, 1])
print("R-squared for Staffing Needs:", r2_staffing_needs)

#got a good accuracy score for and r2 square and stuff lets gooooo

#adding min sample leaf didnt help accuracy at all

#now need to create a dataframe that can hold any future predictions added
#start and end times
start_time = '2025-03-01 01:00:00'
end_time = '2025-03-08 01:00:00'

#Generate future_intervals with the same length as future_predictions_rf_pen_inf
future_intervals = pd.date_range(start=start_time, end=end_time, freq='30min')

future_data_rf_pen_inf = pd.DataFrame({'Interval': future_intervals})


future_data_rf_pen_inf['hour'] = future_data_rf_pen_inf['Interval'].dt.hour
future_data_rf_pen_inf['year'] = future_data_rf_pen_inf['Interval'].dt.year
future_data_rf_pen_inf['month'] = future_data_rf_pen_inf['Interval'].dt.month
future_data_rf_pen_inf['day'] = future_data_rf_pen_inf['Interval'].dt.weekday

#now make predictions using the trained forest model
future_predictions_rf_pen_inf = fclf.predict(future_data_rf_pen_inf[['hour', 'year', 'month','day']]) #same as features column above

#create output dataFrame:

forecast_rf_pen_inf = pd.DataFrame({'Interval': future_intervals,
                               'Predicted Student Count': future_predictions_rf_pen_inf[:, 0], #0 will but the prediction in the firs column
                               'Predicted Staffing Needs': future_predictions_rf_pen_inf[:, 1]})  # 1 puts prediction in the 2nd column
# Display the output:
display(forecast_rf_pen_inf )

forecast_rf_pen_inf .to_csv("forecast_rf_pen_inf .csv", index=False)

"""Now going to build the predtive models

Attempt 1: Pygam
"""

#need to make sure you have pygam installed

#make sure to comment this box out once installed

#!pip install pygam

#!pip install scipy==1.9.3 #need to get a downgraded version of scipy or else the gam functions wont work

#comment out once installed

"""Now going to use pygam on the full data set and see the results

MODEL 2 attempt: xgboost
"""

#no dice with xgboost so delted code :(

"""MODEL Test 3: PROPHET"""

#!pip install prophet # Only use this line if prophet is not already installed

#PROPHET YEAAAAAAAA

#going to do this by using pygam, then next well try using pygam)

#conda install libpython m2w64-toolchain -c msys2
#%pip install prophet # Only use this line if prophet is not already installed
#py -m pip install prophet
#python -m ensurepip --default-pip
#py -m pip install python-docx pyautogui


#%pip install prophet # Only use this line if prophet is not already installed

#was able to run the above statement in the console after adding this path C:\Users\fyoun\anaconda3\Scripts on computer paths i guess idk
#either way its working now, so should be able to run prophet

import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out pre_k1 data from combined dataset)
prek1_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Pre-K1']

#keep only the dates and y vlaues
prek1_data_proph = prek1_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
prek1_data_proph = pd.DataFrame(prek1_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

prek1_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

prek1_model_proph.fit(prek1_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_prek1 = prek1_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
prek1_forecast_proph = prek1_model_proph.predict(future_prek1)

prek1_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_prek1 = prek1_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_prek1)

final_forecast_week_prek1.to_csv("final_forecast_week_prek1.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_prek1_proph =  prek1_model_proph.plot(prek1_forecast_proph)
fig_prek1_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_prek1_proph = prek1_model_proph.plot_components(prek1_forecast_proph)
fig_prek1_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

"""Final concensus: Going to go with prophet for simplicity sake. I dont think the interation between staffing needs and the date is complex enough to justify using pygam

Next step: calculate the remainder of the 1 week staffing needs forecasts
"""

#Prophet forecast for Pre-K2
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
prek2_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Pre-K2']

#keep only the dates and y vlaues
prek2_data_proph = prek2_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
prek2_data_proph = pd.DataFrame(prek2_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

prek2_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

prek2_model_proph.fit(prek2_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_prek2 = prek2_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
prek2_forecast_proph = prek2_model_proph.predict(future_prek2)

prek2_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_prek2 = prek2_forecast_proph[['ds','yhat']][-336:] #.round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_prek2)

final_forecast_week_prek2.to_csv("final_forecast_week_prek2.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_prek2_proph =  prek2_model_proph.plot(prek2_forecast_proph)
fig_prek2_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_prek2_proph = prek2_model_proph.plot_components(prek2_forecast_proph)
fig_prek2_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Pennie Preschool
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
pen_pre_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Pennie Preschool 1']

#keep only the dates and y vlaues
pen_pre_data_proph = pen_pre_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
pen_pre_data_proph = pd.DataFrame(pen_pre_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

pen_pre_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

pen_pre_model_proph.fit(pen_pre_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_pen_pre = pen_pre_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
pen_pre_forecast_proph = pen_pre_model_proph.predict(future_pen_pre)

pen_pre_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_pen_pre = pen_pre_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_pen_pre)

final_forecast_week_pen_pre.to_csv("final_forecast_week_pen_pre.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_pen_pre_proph =  pen_pre_model_proph.plot(pen_pre_forecast_proph)
fig_pen_pre_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_pen_pre_proph = pen_pre_model_proph.plot_components(pen_pre_forecast_proph)
fig_pen_pre_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Grampy Tom Multi-Age
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
gramp_multi_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Grampy Tom Multi-Age']

#keep only the dates and y vlaues
gramp_multi_data_proph = gramp_multi_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
gramp_multi_data_proph = pd.DataFrame(gramp_multi_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

gramp_multi_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

gramp_multi_model_proph.fit(gramp_multi_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_gramp_multi = gramp_multi_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
gramp_multi_forecast_proph = gramp_multi_model_proph.predict(future_gramp_multi)

gramp_multi_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_gramp_multi = gramp_multi_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_gramp_multi)

final_forecast_week_gramp_multi.to_csv("final_forecast_week_gramp_multi.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_gramp_multi_proph =  gramp_multi_model_proph.plot(gramp_multi_forecast_proph)
fig_gramp_multi_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_gramp_multi_proph = gramp_multi_model_proph.plot_components(gramp_multi_forecast_proph)
fig_gramp_multi_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Pennie Toddlers
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
pen_tod_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Pennie Toddlers']

#keep only the dates and y vlaues
pen_tod_data_proph = pen_tod_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
pen_tod_data_proph = pd.DataFrame(pen_tod_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

pen_tod_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

pen_tod_model_proph.fit(pen_tod_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_pen_tod = pen_tod_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
pen_tod_forecast_proph = pen_tod_model_proph.predict(future_pen_tod)

pen_tod_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_pen_tod = pen_tod_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_pen_tod)

final_forecast_week_pen_tod.to_csv("final_forecast_week_pen_tod.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_pen_tod_proph =  pen_tod_model_proph.plot(pen_tod_forecast_proph)
fig_pen_tod_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_pen_tod_proph = pen_tod_model_proph.plot_components(pen_tod_forecast_proph)
fig_pen_tod_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Henry Toddlers
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
henr_tod_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Henry Toddlers']

#keep only the dates and y vlaues
henr_tod_data_proph = henr_tod_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
henr_tod_data_proph = pd.DataFrame(henr_tod_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

henr_tod_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

henr_tod_model_proph.fit(henr_tod_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_henr_tod = henr_tod_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
henr_tod_forecast_proph = henr_tod_model_proph.predict(future_henr_tod)

henr_tod_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_henr_tod = henr_tod_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_henr_tod)

final_forecast_week_henr_tod.to_csv("final_forecast_week_henr_tod.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_henr_tod_proph =  henr_tod_model_proph.plot(henr_tod_forecast_proph)
fig_henr_tod_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_henr_tod_proph = henr_tod_model_proph.plot_components(henr_tod_forecast_proph)
fig_henr_tod_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Grampy Tom Toddlers
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
gramp_tod_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Grampy Tom Toddlers']

#keep only the dates and y vlaues
gramp_tod_data_proph = gramp_tod_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
gramp_tod_data_proph = pd.DataFrame(gramp_tod_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

gramp_tod_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

gramp_tod_model_proph.fit(gramp_tod_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_gramp_tod = gramp_tod_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
gramp_tod_forecast_proph = gramp_tod_model_proph.predict(future_gramp_tod)

gramp_tod_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_gramp_tod = gramp_tod_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_gramp_tod)

final_forecast_week_gramp_tod.to_csv("final_forecast_week_gramp_tod.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_gramp_tod_proph =  gramp_tod_model_proph.plot(gramp_tod_forecast_proph)
fig_gramp_tod_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_gramp_tod_proph = gramp_tod_model_proph.plot_components(gramp_tod_forecast_proph)
fig_gramp_tod_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Grampy Tom Preschool
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
gramp_pre_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Grampy Tom Preschool']

#keep only the dates and y vlaues
gramp_pre_data_proph = gramp_pre_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
gramp_pre_data_proph = pd.DataFrame(gramp_pre_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

gramp_pre_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

gramp_pre_model_proph.fit(gramp_pre_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_gramp_pre = gramp_pre_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
gramp_pre_forecast_proph = gramp_pre_model_proph.predict(future_gramp_pre)

gramp_pre_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_gramp_pre = gramp_pre_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_gramp_pre)

final_forecast_week_gramp_pre.to_csv("final_forecast_week_gramp_pre.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_gramp_pre_proph =  gramp_pre_model_proph.plot(gramp_pre_forecast_proph)
fig_gramp_pre_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_gramp_pre_proph = gramp_pre_model_proph.plot_components(gramp_pre_forecast_proph)
fig_gramp_pre_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Henry Infants
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
henr_inf_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Henry Infants']

#keep only the dates and y vlaues
henr_inf_data_proph = henr_inf_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
henr_inf_data_proph = pd.DataFrame(henr_inf_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

henr_inf_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

henr_inf_model_proph.fit(henr_inf_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_henr_inf = henr_inf_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
henr_inf_forecast_proph = henr_inf_model_proph.predict(future_henr_inf)

henr_inf_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_henr_inf = henr_inf_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_henr_inf)

final_forecast_week_henr_inf.to_csv("final_forecast_week_henr_inf.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_henr_inf_proph =  henr_inf_model_proph.plot(henr_inf_forecast_proph)
fig_henr_inf_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_henr_inf_proph = henr_inf_model_proph.plot_components(henr_inf_forecast_proph)
fig_henr_inf_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Pennie Infants
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
pen_inf_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Pennie Infants']

#keep only the dates and y vlaues
pen_inf_data_proph = pen_inf_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
pen_inf_data_proph = pd.DataFrame(pen_inf_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

pen_inf_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

pen_inf_model_proph.fit(pen_inf_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_pen_inf = pen_inf_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
pen_inf_forecast_proph = pen_inf_model_proph.predict(future_pen_inf)

pen_inf_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_pen_inf = pen_inf_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_pen_inf)

final_forecast_week_pen_inf.to_csv("final_forecast_week_pen_inf.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_pen_inf_proph =  pen_inf_model_proph.plot(pen_inf_forecast_proph)
fig_pen_inf_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_pen_inf_proph = pen_inf_model_proph.plot_components(pen_inf_forecast_proph)
fig_pen_inf_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#Prophet forecast for Henry Multi-Age
import pandas as pd
import numpy as np
from prophet import Prophet


# Read in data, (filter out  data from combined dataset)
henr_multi_data_proph= ecec_count_full[ecec_count_full['Room'] == 'Henry Multi-Age']

#keep only the dates and y vlaues
henr_multi_data_proph = henr_multi_data_proph[['Interval', 'Staffing Needs']] #filer data set to only keep 2 colums


#recreate the data frame with correct labels
henr_multi_data_proph = pd.DataFrame(henr_multi_data_proph.values, columns = ['ds', 'y']) #ds = Interval, Y= Staffing need

#now we can create our model

henr_multi_model_proph = Prophet(changepoint_prior_scale=0.5) #chaangepoint prior scale needs to be secified, teacher used .5 just to test and see
#this is bbasically saying how 'bendy we want the model' if this number is higer then were going to have a more felxible but also more likley to be overfit model
#the lower the model the less flexible it is but the smoother it is (less likely to be overfit)

henr_multi_model_proph.fit(henr_multi_data_proph)

#now we have a model m thats been fit. Now we can make a prediction

# Create an empty dataframe with dates for future periods (need at least one week)
future_henr_multi = henr_multi_model_proph.make_future_dataframe(periods=336, freq = '0.50h') #did 336 because there are 336 30 minute intervals in a 7 day week
 #freq = '0.50H'documentation make its so that the data is being interpreted in the 30 minute intervals

#should do th ther periods based on how many 30 minute segments there are in a week
# Predict will fill in  empty dataframe wtih forecasts of `y` for the future periods
henr_multi_forecast_proph = henr_multi_model_proph.predict(future_henr_multi)

henr_multi_forecast_proph.head()

#this will gives us all the times from the beginning of our data fram PLUS 336 periods at the end (so we looking forward 365 peroiods)
#then we created forecast based on those time periods, so now if we look at the forecast data fram it wil have all of the time periods plus the extra 365 days plus predictions
#all of terms in the forcecast dataframe come together to create our GAM model
#we really care about trend, yearly, and weekly variables

#this will give us back out 336 periods of forcast at the end of the data frame
final_forecast_week_henr_multi = henr_multi_forecast_proph[['ds','yhat']][-336:].round() #<-rounded because cant have a partial employee. Need whole numbers

display(final_forecast_week_henr_multi)

final_forecast_week_henr_multi.to_csv("final_forecast_week_henr_multi.csv", index=False) #this is the next week forecasted data

#yhat = predicted staff needed
#ds = date and time in 30 minute intervals
#takes place over a 7 day period

#now we want visuals
fig_henr_multi_proph =  henr_multi_model_proph.plot(henr_multi_forecast_proph)
fig_henr_multi_proph.show()

#black dots on figure are the actual observations we can see at the end on the right hand side
#the black dots go away because those last periods are our 365 periods of precictions where we are forecasting
#these periods obviously arent occamplied by an observation because we are predicting what they will look like

#now lets plot out or components
# Plot the components of the forecast
fig_henr_multi_proph = henr_multi_model_proph.plot_components(henr_multi_forecast_proph)
fig_henr_multi_proph.show()

#three figures we get:
#gives us a break down of the trends in the previous figure

#year on year trend
#weekday trend
#days of the year trend

#rest of the forecasts and aggregate totals with both ECEC and Spellman are in Spellman Model